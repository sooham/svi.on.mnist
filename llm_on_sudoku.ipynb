{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_token(model, puzzles, positions, device='cpu'):\n",
    "    \"\"\"\n",
    "    Predict the token at given positions in sudoku puzzles.\n",
    "    \n",
    "    Args:\n",
    "        model: The Sudoku2Vec model\n",
    "        puzzles: Sudoku grids [batch_size, 9, 9]\n",
    "        positions: The positions [batch_size, 2] as [x, y]\n",
    "        device: The device to use for computation\n",
    "    \n",
    "    Returns:\n",
    "        predicted_tokens: The predicted tokens (1-9) based on closest embedding [batch_size]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare inputs - handle both tensors and arrays\n",
    "        if isinstance(positions, torch.Tensor):\n",
    "            position_batch = positions.to(device=device, dtype=torch.long)\n",
    "        else:\n",
    "            position_batch = torch.tensor(positions, dtype=torch.long, device=device)\n",
    "        \n",
    "        if isinstance(puzzles, torch.Tensor):\n",
    "            puzzle_batch = puzzles.to(device=device, dtype=torch.long)\n",
    "        else:\n",
    "            puzzle_batch = torch.tensor(puzzles, dtype=torch.long, device=device)\n",
    "        \n",
    "        batch_size = puzzle_batch.shape[0]\n",
    "        \n",
    "        # Create dummy target tokens (we'll ignore these, just need them for forward pass)\n",
    "        dummy_target = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
    "        \n",
    "        # Use the model's forward method\n",
    "        output, attention, target_token_with_position, _ = model.forward(dummy_target, position_batch, puzzle_batch, mask=True)\n",
    "        # print(f\"DEBUG: output.shape = {output.shape}\")\n",
    "        # print(f\"DEBUG: attention.shape = {attention.shape}\")\n",
    "        # print(f\"DEBUG: target_token_with_position.shape = {target_token_with_position.shape}\")\n",
    "        \n",
    "        # Get the attended output at the target position\n",
    "        # We need to extract the embedding at the target position from the output\n",
    "        target_indices = position_batch[:, 1] * 9 + position_batch[:, 0]  # Convert 2D position to 1D index\n",
    "        # # print(f\"DEBUG: target_indices = {target_indices}\")\n",
    "        predicted_embedding = output[torch.arange(batch_size, device=device), target_indices]  # [batch_size, total_dim]\n",
    "        # print(f\"DEBUG: predicted_embedding.shape = {predicted_embedding.shape}\")\n",
    "        \n",
    "        # Get all token embeddings (0-9)\n",
    "        all_tokens = torch.arange(0, 10, dtype=torch.long, device=device)\n",
    "        all_token_embeddings = model.embed(all_tokens)  # [10, embedding_dim]\n",
    "        # print(f\"DEBUG: all_token_embeddings.shape = {all_token_embeddings.shape}\")\n",
    "        # print(f\"DEBUG: model.embedding_dim = {model.embedding_dim}\")\n",
    "        \n",
    "        # Extract only the token embedding part (exclude position info)\n",
    "        # predicted_embedding is [batch_size, total_dim] where total_dim = embedding_dim + 2\n",
    "        # We only want the first embedding_dim dimensions\n",
    "        predicted_token_part = predicted_embedding[:, :model.embedding_dim]  # [batch_size, embedding_dim]\n",
    "        \n",
    "        # Find closest embedding using cosine similarity\n",
    "        # Normalize embeddings\n",
    "        predicted_embedding_norm = torch.nn.functional.normalize(predicted_token_part, p=2, dim=-1)  # [batch_size, embedding_dim]\n",
    "        all_token_embeddings_norm = torch.nn.functional.normalize(all_token_embeddings, p=2, dim=-1)  # [10, embedding_dim]\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarities = torch.matmul(predicted_embedding_norm, all_token_embeddings_norm.T)  # [batch_size, 10]\n",
    "        predicted_tokens = torch.argmax(similarities, dim=-1)  # tokens are 0-9, [batch_size]\n",
    "        \n",
    "        return predicted_tokens\n",
    "\n",
    "# Test model accuracy\n",
    "# Get predictions for all validation samples in batch\n",
    "TEST_SIZE = 100\n",
    "test_target, test_position, test_puzzles, test_original_puzzle = generator.generate_target_context_pairs(size=TEST_SIZE)\n",
    "print(test_target)\n",
    "all_predictions = predict_token(model, test_puzzles, test_position, device=device)\n",
    "\n",
    "# Get actual values at the positions\n",
    "all_actuals = []\n",
    "for i in range(len(test_puzzles)):\n",
    "    pos_x, pos_y = test_position[i][0].item(), test_position[i][1].item()\n",
    "    actual_token = test_puzzles[i][pos_y, pos_x].item()\n",
    "    all_actuals.append(actual_token)\n",
    "\n",
    "all_actuals = torch.tensor(all_actuals, device=device)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (all_predictions == all_actuals).sum().item()\n",
    "total = len(all_predictions)\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Correct: {correct}/{total}\")\n",
    "\n",
    "# Create confusion matrix manually\n",
    "# Tokens are 1-9\n",
    "cm = np.zeros((9, 9), dtype=int)\n",
    "all_predictions_cpu = all_predictions.cpu().numpy()\n",
    "all_actuals_cpu = all_actuals.cpu().numpy()\n",
    "\n",
    "for actual, pred in zip(all_actuals_cpu, all_predictions_cpu):\n",
    "    cm[actual - 1, pred - 1] += 1\n",
    "\n",
    "# Plot confusion matrix using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(cm, cmap='Blues', aspect='auto')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Count', rotation=270, labelpad=20)\n",
    "\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(np.arange(9))\n",
    "ax.set_yticks(np.arange(9))\n",
    "ax.set_xticklabels(list(range(1, 10)))\n",
    "ax.set_yticklabels(list(range(1, 10)))\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        text = ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", \n",
    "                      color=\"black\" if cm[i, j] < cm.max() / 2 else \"white\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Predicted Token', fontsize=12)\n",
    "ax.set_ylabel('Actual Token', fontsize=12)\n",
    "ax.set_title(f'Confusion Matrix (Accuracy: {accuracy:.4f})', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "def visualize_attention(model, puzzle, target, position, device='cpu'):\n",
    "    \"\"\"\n",
    "    Visualize the attention weights for each head in the model.\n",
    "    \n",
    "    Args:\n",
    "        model: The Sudoku2Vec model\n",
    "        puzzle: A single sudoku grid [9, 9]\n",
    "        target: The target token (scalar)\n",
    "        position: The position [2] as [x, y]\n",
    "        device: The device to use for computation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare inputs (add batch dimension)\n",
    "        target_batch = torch.tensor([target], dtype=torch.long, device=device)\n",
    "        position_batch = torch.tensor([position], dtype=torch.long, device=device)\n",
    "        puzzle_batch = torch.tensor([puzzle], dtype=torch.long, device=device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        batch_size = 1\n",
    "        target_token_embeddings = model.embed(target_batch)\n",
    "        target_position_vectors = model.pe.get_embedding_for_position(position_batch)\n",
    "        target_token_with_position = torch.cat([target_token_embeddings, target_position_vectors], dim=-1)\n",
    "        \n",
    "        # Mask the target in the grid\n",
    "        sudoku_grid_masked = puzzle_batch.clone()\n",
    "        sudoku_grid_masked[0, position[1], position[0]] = 0\n",
    "        \n",
    "        # Get grid embeddings\n",
    "        sudoku_grid_embeddings = model.embed(sudoku_grid_masked)\n",
    "        sudoku_grid_with_position = model.pe(sudoku_grid_embeddings)\n",
    "        \n",
    "        # Reshape grid to sequence\n",
    "        grid_seq = sudoku_grid_with_position.view(batch_size, 81, model.total_dim)\n",
    "        \n",
    "        # Get attention weights from the model\n",
    "        _, attention = model.mha(grid_seq, return_attention=True)\n",
    "        \n",
    "        # Reshape attention weights to grid format\n",
    "        # attention shape is [batch, num_heads, seq_len, seq_len]\n",
    "        # Get the attention for the specific position (x, y)\n",
    "        position_idx = position[1] * 9 + position[0]  # Convert 2D position to 1D index\n",
    "        attention_weights = attention.squeeze(0)[:, position_idx, :]  # [num_heads, 81]\n",
    "        \n",
    "        # Validate that attention sums to 1 for each head\n",
    "        attention_sums = attention_weights.sum(dim=-1)\n",
    "        print(f\"Attention sums per head: {attention_sums.cpu().float().numpy()}\")\n",
    "        assert torch.allclose(attention_sums, torch.ones_like(attention_sums), atol=1e-5), \\\n",
    "            f\"Attention weights do not sum to 1! Sums: {attention_sums}\"\n",
    "        \n",
    "        attention_grids = attention_weights.view(model.num_heads, 9, 9).cpu().float().numpy()\n",
    "        # Plot attention maps for each head\n",
    "        fig, axes = plt.subplots(2, (model.num_heads + 1) // 2, figsize=(15, 6))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for head_idx in range(model.num_heads):\n",
    "            ax = axes[head_idx]\n",
    "            im = ax.imshow(attention_grids[head_idx], cmap='hot', interpolation='nearest')\n",
    "            ax.set_title(f'Head {head_idx + 1}')\n",
    "            ax.set_xlabel('Column')\n",
    "            ax.set_ylabel('Row')\n",
    "            \n",
    "            # Add grid values as text\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    text_color = 'white' if attention_grids[head_idx, i, j] > 0.5 else 'black'\n",
    "                    ax.text(j, i, f'{puzzle[i, j]}', ha='center', va='center', \n",
    "                           color=text_color, fontsize=8, weight='bold')\n",
    "            \n",
    "            # Mark target position\n",
    "            ax.plot(position[0], position[1], 'b*', markersize=15, markeredgecolor='cyan', markeredgewidth=2)\n",
    "            \n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.suptitle(f'Attention Maps for Target={target} at Position ({position[0]}, {position[1]})', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "example_idx = random.randint(0, 100)\n",
    "example_puzzle = val_puzzles[example_idx].cpu().numpy()\n",
    "example_target = val_target[example_idx].item()\n",
    "example_position = val_position[example_idx].cpu().numpy()\n",
    "\n",
    "print(f\"\\n=== Visualizing Attention ===\")\n",
    "print(f\"Puzzle:\\n{example_puzzle}\")\n",
    "print(f\"Target: {example_target} at position {example_position}\")\n",
    "\n",
    "# Get prediction\n",
    "predicted_token = predict_token(model, [example_puzzle], [example_position], device=device)[0].item()\n",
    "print(f\"Predicted: {predicted_token}, Actual: {example_target}\")\n",
    "\n",
    "visualize_attention(model, example_puzzle, example_target, example_position, device=device)\n",
    "\n",
    "# DEBUG MODE TEST: Run loss() with debug=True on one input\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING DEBUG MODE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select one sample from the validation set\n",
    "debug_sample_idx = 0\n",
    "debug_target = val_target[debug_sample_idx:debug_sample_idx+1]\n",
    "debug_position = val_position[debug_sample_idx:debug_sample_idx+1]\n",
    "debug_puzzle = val_puzzles[debug_sample_idx:debug_sample_idx+1]\n",
    "\n",
    "print(f\"\\nRunning loss() with debug=True on one validation sample...\")\n",
    "print(f\"Target: {debug_target.item()}\")\n",
    "print(f\"Position: ({debug_position[0, 0].item()}, {debug_position[0, 1].item()})\")\n",
    "print(f\"Puzzle shape: {debug_puzzle.shape}\")\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Run loss with debug=True\n",
    "with torch.no_grad():\n",
    "    loss, contrastive_loss, cosine_loss, accuracy = model.loss(\n",
    "        debug_target.long().to(device), \n",
    "        debug_position.long().to(device), \n",
    "        debug_puzzle.long().to(device),\n",
    "        negative_samples=2,\n",
    "        debug=True\n",
    "    )\n",
    "\n",
    "print(f\"\\nLoss Computation Complete:\")\n",
    "print(f\"  Total Loss: {loss.item():.4f}\")\n",
    "print(f\"  Contrastive Loss: {contrastive_loss.item():.4f}\")\n",
    "print(f\"  Cosine Loss: {cosine_loss.item():.4f}\")\n",
    "print(f\"  Accuracy: {accuracy.item():.4f} ({accuracy.item()*100:.2f}%)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualize embeddings after training\n",
    "print(\"=\"*80)\n",
    "print(\"VISUALIZING EMBEDDINGS AFTER TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get all token embeddings (0-9)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_tokens = torch.arange(0, 10, dtype=torch.long, device=device)\n",
    "    all_embeddings = model.embed(all_tokens).float().cpu().numpy()  # [10, embedding_dim]\n",
    "\n",
    "print(f\"Embedding shape: {all_embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {model.embedding_dim}\")\n",
    "\n",
    "# Create separate plots for each token\n",
    "embedding_dim = all_embeddings.shape[1]\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "# Create a grid of subplots (2 rows x 5 columns for 10 tokens)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for token_idx in range(10):\n",
    "    ax = axes[token_idx]\n",
    "    x = np.arange(embedding_dim)\n",
    "    \n",
    "    # Plot bar chart for this token's embedding\n",
    "    ax.bar(x, all_embeddings[token_idx], color=colors[token_idx], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Dimension', fontsize=10)\n",
    "    ax.set_ylabel('Value', fontsize=10)\n",
    "    ax.set_title(f'Token {token_idx} Embedding', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'{i}' for i in range(embedding_dim)], fontsize=8)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Add statistics to each plot\n",
    "    mean_val = all_embeddings[token_idx].mean()\n",
    "    std_val = all_embeddings[token_idx].std()\n",
    "    ax.text(0.02, 0.98, f'μ={mean_val:.2f}, σ={std_val:.2f}', \n",
    "            transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print embedding statistics\n",
    "print(\"\\nEmbedding Statistics:\")\n",
    "print(f\"  Mean value: {all_embeddings.mean():.4f}\")\n",
    "print(f\"  Std value: {all_embeddings.std():.4f}\")\n",
    "print(f\"  Min value: {all_embeddings.min():.4f}\")\n",
    "print(f\"  Max value: {all_embeddings.max():.4f}\")\n",
    "print(f\"  Mean norm per token: {np.linalg.norm(all_embeddings, axis=1).mean():.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
