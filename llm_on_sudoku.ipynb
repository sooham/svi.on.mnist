{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudoku import Sudoku, SudokuGenerator\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "ATTENTION_DIM = 9\n",
    "N_HEADS = 9\n",
    "EMBEDDING_DIM = 5\n",
    "TRAIN_PUZZLES = 10000\n",
    "VAL_PUZZLES = 512\n",
    "BATCH_SIZE = 512\n",
    "VALIDATE_PERIOD = 10  # Run validation every N epochs\n",
    "CHECKPOINT_PERIOD = 10  # Save checkpoint every N epochs\n",
    "CHECKPOINT_DIR = \"./sudoku_checkpoints\"  # Directory to save checkpoints\n",
    "LOAD_CHECKPOINT = None  # Path to checkpoint to load, or None to start fresh\n",
    "SAVE_CHECKPOINT = True\n",
    "SAMPLES_PER_PUZZLE = 3\n",
    "NEGATIVE_SAMPLES_SIZE = 1\n",
    "USE_NEGATIVE_SAMPLES = False\n",
    "\n",
    "assert ATTENTION_DIM % N_HEADS == 0\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "def get_checkpoint_filename(epoch=None):\n",
    "    \"\"\"Generate checkpoint filename with hyperparameters\"\"\"\n",
    "    filename = f\"sudoku_emb{EMBEDDING_DIM}_att{ATTENTION_DIM}_h{N_HEADS}_bs{BATCH_SIZE}_lr{LEARNING_RATE}\"\n",
    "    if epoch is not None:\n",
    "        filename += f\"_epoch{epoch}\"\n",
    "    else:\n",
    "        filename += \"_final\"\n",
    "    filename += \".pt\"\n",
    "    return os.path.join(CHECKPOINT_DIR, filename)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # for a 9 by 9 sudoku grid\n",
    "    # subdivide a unit circle into 81 sections\n",
    "    # and return x, y coordinates of that output\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Create a grid of positions (0-8 for both x and y)\n",
    "        x_coords = torch.arange(0, 9).unsqueeze(0).repeat(9, 1)\n",
    "        y_coords = torch.arange(0, 9).unsqueeze(1).repeat(1, 9)\n",
    "        \n",
    "        # Convert grid positions to linear indices (0-80)\n",
    "        linear_indices = y_coords * 9 + x_coords  # shape: (9, 9)\n",
    "        \n",
    "        # Convert linear indices to angles on unit circle\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (9, 9)\n",
    "        \n",
    "        # Compute x, y coordinates on unit circle\n",
    "        x_circle = torch.cos(angles)\n",
    "        y_circle = torch.sin(angles)\n",
    "        \n",
    "        # Stack and add batch dimension\n",
    "        pos_encoding = torch.stack([x_circle, y_circle], dim=-1).unsqueeze(0)  # shape: (1, 9, 9, 2)\n",
    "        self.register_buffer('pos_encoding', pos_encoding)\n",
    "    \n",
    "    def get_embedding_for_position(self, pos):\n",
    "        # input (batch, 2) where pos[:, 0] is x and pos[:, 1] is y\n",
    "        # Convert to linear indices\n",
    "        linear_indices = pos[:, 1] * 9 + pos[:, 0]  # shape: (batch,)\n",
    "        \n",
    "        # Convert to angles on unit circle\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (batch,)\n",
    "        \n",
    "        # Compute x, y coordinates on unit circle\n",
    "        x_circle = torch.cos(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        y_circle = torch.sin(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        \n",
    "        return torch.cat([x_circle, y_circle], dim=1)  # shape: (batch, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is a (batch, 9, 9, embedding_dim) grid\n",
    "        # output (batch, 9, 9, embedding_dim + 2) grid by adding pos_encoding to x\n",
    "        batch_size = x.shape[0]\n",
    "        pos_expanded = self.pos_encoding.repeat(batch_size, 1, 1, 1)\n",
    "        # Concatenate along the last dimension: (batch, 9, 9, embedding_dim + 2)\n",
    "        return torch.cat([x, pos_expanded], dim=-1)\n",
    "    \n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "# Helper function to support different mask shapes.\n",
    "# Output shape supports (batch_size, number of heads, seq length, seq length)\n",
    "# If 2D: broadcasted over batch size and number of heads\n",
    "# If 3D: broadcasted over number of heads\n",
    "# If 4D: leave as is\n",
    "def expand_mask(mask):\n",
    "    assert mask.ndim >= 2, \"Mask must be at least 2-dimensional with seq_length x seq_length\"\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    while mask.ndim < 4:\n",
    "        mask = mask.unsqueeze(0)\n",
    "    return mask\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # stack all weight matrices 1...h together for efficiency\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, input_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        if mask is not None:\n",
    "            mask = expand_mask(mask)\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # seperate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
    "        qkv = qkv.permute(0,2,1,3) # [batch, head, seqlen, dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0,2,1,3) # [batch, seqlen, head, dims]\n",
    "        values = values.reshape(batch_size, seq_length, self.embed_dim)\n",
    "        o = self.o_proj(values) # [batch, seq_length, 81]\n",
    "\n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o\n",
    "\n",
    "class Sudoku2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, attention_dim=ATTENTION_DIM, num_heads=N_HEADS, device='cpu'):\n",
    "        super(Sudoku2Vec, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.pe = PositionalEncoding()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim) # this will provide the key queries and values\n",
    "        self.total_dim = self.embedding_dim + 2\n",
    "\n",
    "        self.mha = MultiheadAttention(\n",
    "            input_dim=self.total_dim,\n",
    "            embed_dim=attention_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Move model to device\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, target, position, sudoku_grid, mask=True):\n",
    "        # target - the token in the target blank space we try to predict shape [batch] i.e [0, 3, 3, 5, 1, ...]\n",
    "        # position - the (x, y) position of the target shape [batch, 2] - [[1, 1], [0, 3], [7,7], ...]\n",
    "        # sudoku_grid - the sudoku grid for the problem with target we want to predict shape [batch, 9, 9]\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        target_token_embeddings = self.embed(target) # shape [batch, embedding_dim]\n",
    "        target_position_vectors = self.pe.get_embedding_for_position(position) # [batch, 2]\n",
    "        target_token_with_position = torch.cat([target_token_embeddings, target_position_vectors], dim=-1)  # shape [batch, total_dim]\n",
    "\n",
    "        # mask the target in the grid\n",
    "        sudoku_grid_masked = sudoku_grid\n",
    "        if mask:\n",
    "            batch_indices = torch.arange(sudoku_grid.shape[0], device=self.device)\n",
    "            sudoku_grid_masked = sudoku_grid.clone()\n",
    "            sudoku_grid_masked[batch_indices, position[:, 1], position[:, 0]] = 0 # 0 is a mask token aka blank\n",
    "        \n",
    "        masked_sudoku_grid_embeddings = self.embed(sudoku_grid_masked)\n",
    "        masked_sudoku_grid_with_position = self.pe(masked_sudoku_grid_embeddings) # shape [batch, 9, 9, total_dim]\n",
    "        # Reshape grid to sequence: [batch, 81, total_dim]\n",
    "        masked_grid_seq = masked_sudoku_grid_with_position.view(batch_size, 81, self.total_dim)\n",
    "\n",
    "        grid_seq_embeddings = self.embed(sudoku_grid)\n",
    "        grid_seq_embeddings = grid_seq_embeddings.view(batch_size, 81, self.embedding_dim) \n",
    "        \n",
    "        # Query from target token: [batch, 1, total_dim]\n",
    "        # query = target_token_with_position.unsqueeze(1)\n",
    "\n",
    "        output, attention = self.mha(masked_grid_seq, return_attention=True)\n",
    "        # output is shape [batch, 81, total_dim]\n",
    "        \n",
    "        return output, attention, target_token_with_position, grid_seq_embeddings\n",
    "    \n",
    "    def loss(self, target, position, sudoku_grid, negative_samples=NEGATIVE_SAMPLES_SIZE, use_negative_samples=USE_NEGATIVE_SAMPLES, debug=False):\n",
    "        \"\"\"\n",
    "        Compute contrastive loss for the model.\n",
    "        \n",
    "        The loss combines two components:\n",
    "        1. Margin-based Contrastive Loss: Encourages the model to distinguish between correct (positive) \n",
    "           and incorrect (negative) token predictions by maximizing positive scores and minimizing negative scores.\n",
    "           (Optional - controlled by use_negative_samples parameter)\n",
    "        2. Cosine Similarity Loss: Directly maximizes the cosine similarity between predicted and \n",
    "           ground truth embeddings.\n",
    "        \n",
    "        Mathematical formulation:\n",
    "        \n",
    "        For a batch of examples, let:\n",
    "        - z_i = output embedding at target position i (from attention output)\n",
    "        - p_i = ground truth embedding at target position i (from target token embedding)\n",
    "        - n_{i,j} = j-th negative sample embedding for example i\n",
    "        \n",
    "        Cosine Similarity (computed ONLY at target position):\n",
    "            cos_sim(z_i, p_i) = (z_i · p_i) / (||z_i|| ||p_i||)\n",
    "        \n",
    "        Margin-based Contrastive Loss (per example i) - OPTIONAL:\n",
    "            L_contrastive = max(0, margin - cos_sim(z_i, p_i)) + Σ_j max(0, cos_sim(z_i, n_{i,j}))\n",
    "        \n",
    "        This loss:\n",
    "        - Penalizes positive scores below the margin (encourages positive scores to be high)\n",
    "        - Penalizes positive negative scores (encourages negative scores to be low/negative)\n",
    "        \n",
    "        Cosine Loss:\n",
    "            L_cosine = 1 - mean(cos_sim(z_i, p_i))\n",
    "        \n",
    "        Total Loss:\n",
    "            If use_negative_samples is True:\n",
    "                L_total = L_contrastive + L_cosine\n",
    "            If use_negative_samples is False:\n",
    "                L_total = L_cosine\n",
    "        \n",
    "        Relationship between the two losses:\n",
    "        - Both losses encourage high cosine similarity between predicted and ground truth embeddings\n",
    "        - L_contrastive uses a margin-based objective: it ensures positive similarity is high (above margin)\n",
    "          and negative similarities are low (below 0)\n",
    "        - L_cosine provides a direct gradient signal to maximize positive similarity without \n",
    "          considering negatives\n",
    "        - Together, they provide both relative ranking (contrastive) and absolute alignment (cosine)\n",
    "        \n",
    "        Args:\n",
    "            target: Ground truth tokens [batch]\n",
    "            position: Target positions [batch, 2]\n",
    "            sudoku_grid: Sudoku grids [batch, 9, 9]\n",
    "            negative_samples: Number of negative samples per positive example (only used if use_negative_samples=True)\n",
    "            use_negative_samples: Whether to use negative samples for contrastive loss\n",
    "            debug: If True, visualize embeddings, cosine similarity, sudoku grids, and attention maps\n",
    "        \n",
    "        Returns:\n",
    "            total_loss: Combined loss value\n",
    "            contrastive_loss: Margin-based contrastive loss component (0 if use_negative_samples=False)\n",
    "            cosine_loss: Cosine similarity loss component\n",
    "            accuracy: Prediction accuracy based on closest cosine similarity to vocab embeddings\n",
    "        \"\"\"\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        # Forward pass to get output and target embeddings\n",
    "        output, attention, target_token_with_position, grid_embeddings_flat = self.forward(target, position, sudoku_grid, mask=True)\n",
    "        # output is shape [batch, seq_length, total_dim]\n",
    "        \n",
    "        # Extract only the embedding portion (without position vectors) from output\n",
    "        # output is [batch, 81, total_dim] where total_dim = embedding_dim + 2\n",
    "        # We want only the first embedding_dim dimensions\n",
    "        output_embeddings = output[:, :, :self.embedding_dim]  # shape [batch, 81, embedding_dim]\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity computation\n",
    "        output_norm = F.normalize(output_embeddings, p=2, dim=-1)  # [batch, 81, embedding_dim]\n",
    "        grid_norm = F.normalize(grid_embeddings_flat, p=2, dim=-1)  # [batch, 81, embedding_dim]\n",
    "        \n",
    "        # === Extract embeddings at target positions ===\n",
    "        batch_indices = torch.arange(batch_size, device=self.device)\n",
    "        # Convert 2D positions to linear indices\n",
    "        linear_indices = position[:, 1] * 9 + position[:, 0]  # [batch]\n",
    "        \n",
    "        # Get output embeddings at target positions (z_i)\n",
    "        output_at_target = output_embeddings[batch_indices, linear_indices, :]  # [batch, embedding_dim]\n",
    "        output_at_target_norm = F.normalize(output_at_target, p=2, dim=-1)  # [batch, embedding_dim]\n",
    "        \n",
    "        # Get ground truth embeddings at target positions (p_i)\n",
    "        ground_truth_at_target = grid_embeddings_flat[batch_indices, linear_indices, :]  # [batch, embedding_dim]\n",
    "        ground_truth_at_target_norm = F.normalize(ground_truth_at_target, p=2, dim=-1)  # [batch, embedding_dim]\n",
    "        \n",
    "        # Compute positive cosine similarity ONLY at target position\n",
    "        # This is cos_sim(z_i, p_i) where i is the target position\n",
    "        positive_scores = (output_at_target_norm * ground_truth_at_target_norm).sum(dim=-1)  # [batch]\n",
    "        \n",
    "        # Compute positive scores for all positions (for debugging/visualization)\n",
    "        positive_scores_per_position = (output_norm * grid_norm).sum(dim=-1)  # [batch, 81]\n",
    "        \n",
    "        # === Margin-based Contrastive Loss (Optional) ===\n",
    "        margin = 1.0  # Target margin for positive scores\n",
    "        \n",
    "        # Loss for positive scores: penalize if below margin\n",
    "        # max(0, margin - positive_score) encourages positive_score >= margin\n",
    "        positive_loss = torch.clamp(margin - positive_scores, min=0).mean()\n",
    "        vocab_size = self.embed.num_embeddings\n",
    "        \n",
    "        if use_negative_samples:\n",
    "            # === Negative sampling for contrastive loss ===\n",
    "            # Generate negative samples (n_{i,j})\n",
    "            # Sample random tokens that are not the target\n",
    "            negative_targets = []\n",
    "            for i in range(batch_size):\n",
    "                # Sample negative_samples tokens different from target[i]\n",
    "                neg_samples = []\n",
    "                while len(neg_samples) < negative_samples:\n",
    "                    neg_token = torch.randint(0, vocab_size, (1,), device=self.device)\n",
    "                    if neg_token.item() != target[i].item():\n",
    "                        neg_samples.append(neg_token)\n",
    "                negative_targets.append(torch.cat(neg_samples))\n",
    "            negative_targets = torch.stack(negative_targets)  # [batch, negative_samples]\n",
    "            \n",
    "            # Get embeddings for negative samples (only the embedding part, no position)\n",
    "            negative_embeddings = self.embed(negative_targets)  # [batch, negative_samples, embedding_dim]\n",
    "            \n",
    "            # Compute cosine similarity between output at target position and negative samples\n",
    "            # This is cos_sim(z_i, n_{i,j})\n",
    "            output_at_target_norm_expanded = output_at_target_norm.unsqueeze(1)  # [batch, 1, embedding_dim]\n",
    "            negative_norm = F.normalize(negative_embeddings, p=2, dim=-1)  # [batch, negative_samples, embedding_dim]\n",
    "            negative_scores = (output_at_target_norm_expanded * negative_norm).sum(dim=-1)  # [batch, negative_samples]\n",
    "            \n",
    "            # Loss for negative scores: penalize if above 0\n",
    "            # max(0, negative_score) encourages negative_score <= 0\n",
    "            negative_loss = torch.clamp(negative_scores, min=-1).mean()\n",
    "            \n",
    "            # Combine positive and negative losses\n",
    "            contrastive_loss = negative_loss\n",
    "        else:\n",
    "            # No negative sampling - set negative loss to 0\n",
    "            negative_loss = torch.tensor(0.0, device=self.device, dtype=output.dtype)\n",
    "            contrastive_loss = negative_loss\n",
    "        \n",
    "        # === Cosine Similarity Loss ===\n",
    "        # Simple loss: 1 - cosine similarity (encourages similarity to approach 1)\n",
    "        cosine_loss = positive_loss\n",
    "        \n",
    "        # === Combine both losses ===\n",
    "        # The contrastive loss ensures positive scores are high and negative scores are low (if enabled)\n",
    "        # The cosine loss ensures absolute alignment (positive → 1)\n",
    "        total_loss = contrastive_loss + cosine_loss\n",
    "        \n",
    "        # === Compute Accuracy ===\n",
    "        # For each example in the batch, find which token embedding has highest cosine similarity\n",
    "        # with the output embedding at the target position\n",
    "        \n",
    "        # Get all token embeddings from the embedding layer [vocab_size, embedding_dim]\n",
    "        all_token_embeddings = self.embed.weight  # [vocab_size, embedding_dim]\n",
    "        all_token_embeddings_norm = F.normalize(all_token_embeddings, p=2, dim=-1)  # [vocab_size, embedding_dim]\n",
    "        \n",
    "        # Compute cosine similarity between output at target and all vocab tokens\n",
    "        # output_at_target_norm: [batch, embedding_dim]\n",
    "        # all_token_embeddings_norm: [vocab_size, embedding_dim]\n",
    "        # We want: [batch, vocab_size]\n",
    "        similarity_to_all_tokens = torch.matmul(output_at_target_norm, all_token_embeddings_norm.T)  # [batch, vocab_size]\n",
    "        \n",
    "        # Get the predicted token (argmax of cosine similarities)\n",
    "        predicted_tokens = torch.argmax(similarity_to_all_tokens, dim=-1)  # [batch]\n",
    "        \n",
    "        # Compute accuracy\n",
    "        correct_predictions = (predicted_tokens == target).float()\n",
    "        accuracy = correct_predictions.mean()\n",
    "        \n",
    "        # === Debug Visualization ===\n",
    "        if debug:\n",
    "            \n",
    "            # We'll visualize the first sample in the batch\n",
    "            sample_idx = 0\n",
    "            \n",
    "            # Number colors for sudoku visualization\n",
    "            number_colors = {\n",
    "                1: '#FFB3BA',  # Light red\n",
    "                2: '#FFDFBA',  # Light orange\n",
    "                3: '#FFFFBA',  # Light yellow\n",
    "                4: '#BAFFC9',  # Light green\n",
    "                5: '#BAE1FF',  # Light blue\n",
    "                6: '#D4BAFF',  # Light purple\n",
    "                7: '#FFB3E6',  # Light pink\n",
    "                8: '#C9C9C9',  # Light gray\n",
    "                9: '#FFD4BA',  # Light peach\n",
    "            }\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"DEBUG MODE: Visualizing Model Internals\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # 1. SUDOKU GRID AND TARGET VISUALIZATION\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            \n",
    "            # Original grid\n",
    "            ax = axes[0]\n",
    "            puzzle = sudoku_grid[sample_idx].cpu().numpy()\n",
    "            pos = position[sample_idx].cpu().numpy()\n",
    "            tgt = target[sample_idx].item()\n",
    "            \n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    if puzzle[i, j] != 0:\n",
    "                        color = number_colors[puzzle[i, j]]\n",
    "                        rect = mpatches.Rectangle((j, i), 1, 1, linewidth=0, \n",
    "                                                 edgecolor='none', facecolor=color, alpha=0.6)\n",
    "                        ax.add_patch(rect)\n",
    "            \n",
    "            for i in range(10):\n",
    "                linewidth = 2 if i % 3 == 0 else 0.5\n",
    "                ax.axhline(i, color='black', linewidth=linewidth)\n",
    "                ax.axvline(i, color='black', linewidth=linewidth)\n",
    "            \n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    if puzzle[i, j] != 0:\n",
    "                        ax.text(j + 0.5, i + 0.5, str(puzzle[i, j]), \n",
    "                               ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # Mark target position\n",
    "            ax.plot(pos[0] + 0.5, pos[1] + 0.5, 'r*', markersize=20, markeredgecolor='darkred', markeredgewidth=2)\n",
    "            \n",
    "            ax.set_xlim(0, 9)\n",
    "            ax.set_ylim(0, 9)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(f'Original Sudoku Grid\\nTarget: {tgt} at Position ({pos[0]}, {pos[1]})', fontweight='bold')\n",
    "            \n",
    "            # Masked grid\n",
    "            ax = axes[1]\n",
    "            masked_puzzle = sudoku_grid.clone()\n",
    "            masked_puzzle[sample_idx, pos[1], pos[0]] = 0\n",
    "            masked_puzzle = masked_puzzle[sample_idx].cpu().numpy()\n",
    "            \n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    if masked_puzzle[i, j] != 0:\n",
    "                        color = number_colors[masked_puzzle[i, j]]\n",
    "                        rect = mpatches.Rectangle((j, i), 1, 1, linewidth=0, \n",
    "                                                 edgecolor='none', facecolor=color, alpha=0.6)\n",
    "                        ax.add_patch(rect)\n",
    "            \n",
    "            for i in range(10):\n",
    "                linewidth = 2 if i % 3 == 0 else 0.5\n",
    "                ax.axhline(i, color='black', linewidth=linewidth)\n",
    "                ax.axvline(i, color='black', linewidth=linewidth)\n",
    "            \n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    if masked_puzzle[i, j] != 0:\n",
    "                        ax.text(j + 0.5, i + 0.5, str(masked_puzzle[i, j]), \n",
    "                               ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # Mark target position (empty)\n",
    "            ax.plot(pos[0] + 0.5, pos[1] + 0.5, 'r*', markersize=20, markeredgecolor='darkred', markeredgewidth=2)\n",
    "            \n",
    "            ax.set_xlim(0, 9)\n",
    "            ax.set_ylim(0, 9)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(f'Masked Sudoku Grid (Input to Model)\\nPosition ({pos[0]}, {pos[1]}) is Masked', fontweight='bold')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 2. EMBEDDINGS VISUALIZATION\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "            \n",
    "            # Output embeddings at all positions (reshaped to 9x9 grid)\n",
    "            ax = axes[0, 0]\n",
    "            output_emb_2d = output_embeddings[sample_idx].cpu().detach().float().numpy()  # [81, embedding_dim]\n",
    "            output_emb_grid = output_emb_2d.reshape(9, 9, -1)  # [9, 9, embedding_dim]\n",
    "            # Visualize L2 norm of embeddings\n",
    "            output_norms = np.linalg.norm(output_emb_grid, axis=-1)  # [9, 9]\n",
    "            im = ax.imshow(output_norms, cmap='viridis', aspect='auto')\n",
    "            ax.set_title('Output Embedding Norms (9x9 Grid) - attention output', fontweight='bold')\n",
    "            ax.set_xlabel('Column')\n",
    "            ax.set_ylabel('Row')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            # Mark target position\n",
    "            ax.plot(pos[0], pos[1], 'r*', markersize=20, markeredgecolor='white', markeredgewidth=2)\n",
    "            \n",
    "            # Grid embeddings (ground truth)\n",
    "            ax = axes[0, 1]\n",
    "            grid_emb_2d = grid_embeddings_flat[sample_idx].cpu().detach().float().numpy()  # [81, embedding_dim]\n",
    "            grid_emb_grid = grid_emb_2d.reshape(9, 9, -1)  # [9, 9, embedding_dim]\n",
    "            grid_norms = np.linalg.norm(grid_emb_grid, axis=-1)  # [9, 9]\n",
    "            im = ax.imshow(grid_norms, cmap='viridis', aspect='auto')\n",
    "            ax.set_title('Grid Embedding Norms (Ground Truth) - embedding of the grid not masked', fontweight='bold')\n",
    "            ax.set_xlabel('Column')\n",
    "            ax.set_ylabel('Row')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            # Mark target position\n",
    "            ax.plot(pos[0], pos[1], 'r*', markersize=20, markeredgecolor='white', markeredgewidth=2)\n",
    "            \n",
    "            # Output embedding at target position\n",
    "            ax = axes[1, 0]\n",
    "            output_at_target_vec = output_at_target[sample_idx].cpu().detach().float().numpy()\n",
    "            ax.bar(range(len(output_at_target_vec)), output_at_target_vec)\n",
    "            ax.set_title(f'Output Embedding at Target Position\\n(Dimension: {len(output_at_target_vec)})', fontweight='bold')\n",
    "            ax.set_xlabel('Embedding Dimension')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(alpha=0.3)\n",
    "            \n",
    "            # Ground truth embedding at target position\n",
    "            ax = axes[1, 1]\n",
    "            linear_idx = position[sample_idx, 1] * 9 + position[sample_idx, 0]\n",
    "            gt_at_target_vec = grid_embeddings_flat[sample_idx, linear_idx].cpu().detach().float().numpy()\n",
    "            ax.bar(range(len(gt_at_target_vec)), gt_at_target_vec)\n",
    "            ax.set_title(f'Ground Truth Embedding at Target Position\\n(Token: {tgt})', fontweight='bold')\n",
    "            ax.set_xlabel('Embedding Dimension')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.grid(alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 3. ALL TOKEN EMBEDDINGS VISUALIZATION (NORMALIZED)\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Visualize all token embeddings as a heatmap\n",
    "            ax = axes[0]\n",
    "            all_token_emb_np = all_token_embeddings.cpu().detach().float().numpy()  # [vocab_size, embedding_dim]\n",
    "            im = ax.imshow(all_token_emb_np, cmap='coolwarm', aspect='auto', interpolation='nearest')\n",
    "            ax.set_title('All Token Embeddings (Raw)', fontweight='bold')\n",
    "            ax.set_xlabel('Embedding Dimension')\n",
    "            ax.set_ylabel('Token ID')\n",
    "            ax.set_yticks(range(vocab_size))\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            # Visualize normalized token embeddings\n",
    "            ax = axes[1]\n",
    "            all_token_emb_norm_np = all_token_embeddings_norm.cpu().detach().float().numpy()  # [vocab_size, embedding_dim]\n",
    "            im = ax.imshow(all_token_emb_norm_np, cmap='coolwarm', aspect='auto', interpolation='nearest')\n",
    "            ax.set_title('All Token Embeddings (Normalized)', fontweight='bold')\n",
    "            ax.set_xlabel('Embedding Dimension')\n",
    "            ax.set_ylabel('Token ID')\n",
    "            ax.set_yticks(range(vocab_size))\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 4. COSINE SIMILARITY VISUALIZATION\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            \n",
    "            # Cosine similarity across all positions (reshaped to 9x9 grid)\n",
    "            ax = axes[0]\n",
    "            positive_scores_grid = positive_scores_per_position[sample_idx].view(9, 9).cpu().detach().float().numpy()\n",
    "            im = ax.imshow(positive_scores_grid, cmap='RdYlGn', vmin=-1, vmax=1, aspect='auto')\n",
    "            ax.set_title('Cosine Similarity (Output vs Ground Truth) - All Positions and normed', fontweight='bold')\n",
    "            ax.set_xlabel('Column')\n",
    "            ax.set_ylabel('Row')\n",
    "            \n",
    "            # Add text annotations\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    text = ax.text(j, i, f'{positive_scores_grid[i, j]:.2f}', \n",
    "                                  ha='center', va='center', fontsize=8,\n",
    "                                  color='black' if abs(positive_scores_grid[i, j]) < 0.5 else 'white')\n",
    "            \n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            # Mark target position\n",
    "            ax.plot(pos[0], pos[1], 'r*', markersize=20, markeredgecolor='white', markeredgewidth=2)\n",
    "            \n",
    "            # Cosine similarity between output at target and all vocab tokens\n",
    "            ax = axes[1]\n",
    "            vocab_similarities = similarity_to_all_tokens[sample_idx].cpu().detach().float().numpy()\n",
    "            colors = ['green' if i == tgt else 'blue' if i == predicted_tokens[sample_idx].item() else 'gray' \n",
    "                     for i in range(len(vocab_similarities))]\n",
    "            ax.bar(range(len(vocab_similarities)), vocab_similarities, color=colors, alpha=0.7)\n",
    "            ax.set_title(f'Cosine Similarity: Output @ Target vs All Vocab Tokens\\nGreen=GT({tgt}), Blue=Pred({predicted_tokens[sample_idx].item()})', \n",
    "                        fontweight='bold')\n",
    "            ax.set_xlabel('Token ID')\n",
    "            ax.set_ylabel('Cosine Similarity')\n",
    "            ax.set_xticks(range(len(vocab_similarities)))\n",
    "            ax.grid(alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add legend\n",
    "            legend_elements = [\n",
    "                Patch(facecolor='green', alpha=0.7, label=f'Ground Truth (Token {tgt})'),\n",
    "                Patch(facecolor='blue', alpha=0.7, label=f'Predicted (Token {predicted_tokens[sample_idx].item()})'),\n",
    "                Patch(facecolor='gray', alpha=0.7, label='Other Tokens')\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc='best')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 5. ATTENTION MAPS VISUALIZATION\n",
    "            fig, axes = plt.subplots(2, (self.num_heads + 1) // 2, figsize=(16, 8))\n",
    "            if self.num_heads == 1:\n",
    "                axes = [axes]\n",
    "            else:\n",
    "                axes = axes.flatten()\n",
    "            \n",
    "            # Get attention weights from the forward pass\n",
    "            attention_weights = attention[sample_idx]  # [num_heads, seq_len, seq_len]\n",
    "            linear_idx = position[sample_idx, 1] * 9 + position[sample_idx, 0]\n",
    "            attention_at_target = attention_weights[:, linear_idx, :]  # [num_heads, 81]\n",
    "            attention_grids = attention_at_target.view(self.num_heads, 9, 9).cpu().detach().float().numpy()\n",
    "            \n",
    "            for head_idx in range(self.num_heads):\n",
    "                ax = axes[head_idx]\n",
    "                im = ax.imshow(attention_grids[head_idx], cmap='hot', interpolation='nearest', vmin=0, vmax=attention_grids.max())\n",
    "                ax.set_title(f'Attention Head {head_idx + 1}', fontweight='bold')\n",
    "                ax.set_xlabel('Column')\n",
    "                ax.set_ylabel('Row')\n",
    "                \n",
    "                # Add grid values as text\n",
    "                for i in range(9):\n",
    "                    for j in range(9):\n",
    "                        text_color = 'white' if attention_grids[head_idx, i, j] > attention_grids.max() * 0.5 else 'black'\n",
    "                        ax.text(j, i, f'{puzzle[i, j]}', ha='center', va='center', \n",
    "                               color=text_color, fontsize=8, weight='bold')\n",
    "                \n",
    "                # Mark target position\n",
    "                ax.plot(pos[0], pos[1], 'b*', markersize=15, markeredgecolor='cyan', markeredgewidth=2)\n",
    "                \n",
    "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.suptitle(f'Attention Maps: Query at Position ({pos[0]}, {pos[1]}) attending to all positions', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(f\"\\nDEBUG SUMMARY:\")\n",
    "            print(f\"  Sample Index: {sample_idx}\")\n",
    "            print(f\"  Target Token: {tgt} at Position ({pos[0]}, {pos[1]})\")\n",
    "            print(f\"  Predicted Token: {predicted_tokens[sample_idx].item()}\")\n",
    "            print(f\"  Correct: {predicted_tokens[sample_idx].item() == tgt}\")\n",
    "            \n",
    "            # Get cosine similarity at target position (used in loss)\n",
    "            cos_sim_at_target_loss = positive_scores[sample_idx].item()\n",
    "            \n",
    "            # Get cosine similarity from the per-position computation (for verification)\n",
    "            target_linear_idx = position[sample_idx, 1] * 9 + position[sample_idx, 0]\n",
    "            cos_sim_at_target_viz = positive_scores_per_position[sample_idx, target_linear_idx].item()\n",
    "            \n",
    "            print(f\"  Cosine Similarity (Output @ Target vs GT - used in loss): {float(cos_sim_at_target_loss):.4f}\")\n",
    "            print(f\"  Cosine Similarity (Output @ Target vs GT - from viz): {float(cos_sim_at_target_viz):.4f}\")\n",
    "            print(f\"  Cosine Similarity (Output @ Target vs Predicted): {vocab_similarities[predicted_tokens[sample_idx].item()]:.4f}\")\n",
    "            print(f\"  Contrastive Loss: {float(contrastive_loss.item()):.4f}\")\n",
    "            print(f\"  Cosine Loss: {float(cosine_loss.item()):.4f}\")\n",
    "            print(f\"  Total Loss: {float(total_loss.item()):.4f}\")\n",
    "            print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        return total_loss, contrastive_loss, cosine_loss, accuracy\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "model = Sudoku2Vec(vocab_size=10, embedding_dim=EMBEDDING_DIM, device=device)\n",
    "\n",
    "# Convert model to bfloat16 if supported for better performance and memory efficiency\n",
    "if device.type == 'cuda' and torch.cuda.is_bf16_supported():\n",
    "    model = model.to(dtype=torch.bfloat16)\n",
    "    print(\"✓ Model converted to bfloat16\")\n",
    "elif device.type == 'cpu':\n",
    "    # Modern CPUs support bfloat16\n",
    "    model = model.to(dtype=torch.bfloat16)\n",
    "    print(\"✓ Model converted to bfloat16 (CPU)\")\n",
    "else:\n",
    "    print(\"✓ Model kept in float32 (bfloat16 not supported)\")\n",
    "\n",
    "# Enable cuDNN benchmarking for CUDA (auto-tunes convolution algorithms)\n",
    "if device.type == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"✓ cuDNN benchmarking enabled\")\n",
    "\n",
    "# Create optimizer with fused option if on CUDA for better performance\n",
    "try:\n",
    "    if device.type == 'cuda':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, fused=True)\n",
    "        print(\"✓ Using fused Adam optimizer for CUDA\")\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "        print(\"✓ Using standard Adam optimizer\")\n",
    "except:\n",
    "    # Fallback if fused is not supported\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    print(\"✓ Using standard Adam optimizer (fused not available)\")\n",
    "# Torch compilation removed - was causing issues\n",
    "print(\"✓ Using uncompiled model\")\n",
    "\n",
    "# Setup Mixed Precision Training with bfloat16\n",
    "# bfloat16 is better than float16 for training stability and is supported on modern hardware\n",
    "USE_AMP = True\n",
    "\n",
    "if USE_AMP:\n",
    "    # Determine the best dtype based on device\n",
    "    if device.type == 'cuda':\n",
    "        # CUDA supports both bfloat16 and float16, bfloat16 is preferred for better numerical stability\n",
    "        amp_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "        print(f\"Mixed precision training enabled with {amp_dtype} on CUDA\")\n",
    "    elif device.type == 'mps':\n",
    "        # MPS has limited support for mixed precision, use float16\n",
    "        amp_dtype = torch.float16\n",
    "        print(f\"Mixed precision training enabled with {amp_dtype} on MPS\")\n",
    "    else:\n",
    "        # CPU - bfloat16 is supported on modern CPUs\n",
    "        amp_dtype = torch.bfloat16\n",
    "        print(f\"Mixed precision training enabled with {amp_dtype} on CPU\")\n",
    "    \n",
    "    # Create GradScaler for automatic loss scaling (helps prevent underflow with float16)\n",
    "    # Note: bfloat16 doesn't need scaling as much, but it doesn't hurt\n",
    "    scaler = torch.amp.GradScaler(device.type, enabled=(amp_dtype == torch.float16))\n",
    "    \n",
    "    print(f\"✓ Mixed precision training configured\")\n",
    "    print(f\"  - dtype: {amp_dtype}\")\n",
    "    print(f\"  - gradient scaling: {'enabled' if scaler.is_enabled() else 'disabled (not needed for bfloat16)'}\")\n",
    "else:\n",
    "    # Even with AMP disabled, use bfloat16 if supported for efficiency\n",
    "    if device.type == 'cuda' and torch.cuda.is_bf16_supported():\n",
    "        amp_dtype = torch.bfloat16\n",
    "        print(\"Mixed precision training disabled, using bfloat16\")\n",
    "    elif device.type == 'cpu':\n",
    "        amp_dtype = torch.bfloat16\n",
    "        print(\"Mixed precision training disabled, using bfloat16 (CPU)\")\n",
    "    else:\n",
    "        amp_dtype = torch.float32\n",
    "        print(\"Mixed precision training disabled, using float32\")\n",
    "    scaler = None\n",
    "\n",
    "\n",
    "generator = SudokuGenerator(backend='torch', bit_width='4bit', device=device)\n",
    "target, position, puzzles, original_puzzle = generator.generate_target_context_pairs(size=TRAIN_PUZZLES, k=SAMPLES_PER_PUZZLE, shuffle=True)\n",
    "val_target, val_position, val_puzzles, val_original_puzzle = generator.generate_target_context_pairs(size=VAL_PUZZLES, k=SAMPLES_PER_PUZZLE, shuffle=True)\n",
    "\n",
    "print(f\"Training data shapes:\")\n",
    "print(f\"  target: {target.shape}, dtype: {target.dtype}\")\n",
    "print(f\"  position: {position.shape}, dtype: {position.dtype}\")\n",
    "print(f\"  puzzles: {puzzles.shape}, dtype: {puzzles.dtype}\")\n",
    "print(f\"  original_puzzle: {original_puzzle.shape}, dtype: {original_puzzle.dtype}\")\n",
    "print(f\"\\nValidation data shapes:\")\n",
    "print(f\"  val_target: {val_target.shape}, dtype: {val_target.dtype}\")\n",
    "print(f\"  val_position: {val_position.shape}, dtype: {val_position.dtype}\")\n",
    "print(f\"  val_puzzles: {val_puzzles.shape}, dtype: {val_puzzles.dtype}\")\n",
    "print(f\"  val_original_puzzle: {val_original_puzzle.shape}, dtype: {val_original_puzzle.dtype}\")\n",
    "\n",
    "# print(f\"\\nTraining data context (first few samples):\")\n",
    "# print(f\"  target values: {target[:5]}\")\n",
    "# print(f\"  positions: {position[:5]}\")\n",
    "# print(f\"  puzzles: {puzzles[:5]}\")\n",
    "# print(f\"\\nValidation data context (first few samples):\")\n",
    "# print(f\"  val_target values: {val_target[:5]}\")\n",
    "# print(f\"  val_positions: {val_position[:5]}\")\n",
    "# print(f\"  val_puzzles: {val_puzzles[:5]}\")\n",
    "\n",
    "# Visualize some random sudoku puzzles from training and validation sets\n",
    "def visualize_sudoku(puzzle, title=\"Sudoku Puzzle\"):\n",
    "    \"\"\"Visualize a single sudoku puzzle\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    \n",
    "    # Convert to numpy if tensor\n",
    "    if torch.is_tensor(puzzle):\n",
    "        puzzle = puzzle.cpu().numpy()\n",
    "    \n",
    "    # Draw the grid\n",
    "    for i in range(10):\n",
    "        linewidth = 2 if i % 3 == 0 else 0.5\n",
    "        ax.axhline(i, color='black', linewidth=linewidth)\n",
    "        ax.axvline(i, color='black', linewidth=linewidth)\n",
    "    \n",
    "    # Fill in the numbers\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if puzzle[i, j] != 0:\n",
    "                ax.text(j + 0.5, i + 0.5, str(puzzle[i, j]), \n",
    "                       ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, 9)\n",
    "    ax.set_ylim(0, 9)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Define colors for each number (1-9)\n",
    "number_colors = {\n",
    "    1: '#FFB3BA',  # Light red\n",
    "    2: '#FFDFBA',  # Light orange\n",
    "    3: '#FFFFBA',  # Light yellow\n",
    "    4: '#BAFFC9',  # Light green\n",
    "    5: '#BAE1FF',  # Light blue\n",
    "    6: '#D4BAFF',  # Light purple\n",
    "    7: '#FFB3E6',  # Light pink\n",
    "    8: '#C9C9C9',  # Light gray\n",
    "    9: '#FFD4BA',  # Light peach\n",
    "}\n",
    "\n",
    "# Select 10 random indices from training set\n",
    "train_indices = np.random.choice(len(puzzles), size=min(10, len(puzzles)), replace=False)\n",
    "\n",
    "# Select 10 random indices from validation set\n",
    "val_indices = np.random.choice(len(val_puzzles), size=min(10, len(val_puzzles)), replace=False)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "fig.suptitle('Random Sudoku Puzzles (Top 2 rows: Training, Bottom 2 rows: Validation)', fontsize=16)\n",
    "\n",
    "# Plot training puzzles\n",
    "for idx, train_idx in enumerate(train_indices):\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    puzzle = puzzles[train_idx].cpu().numpy() if torch.is_tensor(puzzles[train_idx]) else puzzles[train_idx]\n",
    "    \n",
    "    # Fill cells with colors based on numbers\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if puzzle[i, j] != 0:\n",
    "                color = number_colors[puzzle[i, j]]\n",
    "                rect = mpatches.Rectangle((j, i), 1, 1, linewidth=0, \n",
    "                                         edgecolor='none', facecolor=color, alpha=0.6)\n",
    "                ax.add_patch(rect)\n",
    "    \n",
    "    # Draw the grid\n",
    "    for i in range(10):\n",
    "        linewidth = 2 if i % 3 == 0 else 0.5\n",
    "        ax.axhline(i, color='black', linewidth=linewidth)\n",
    "        ax.axvline(i, color='black', linewidth=linewidth)\n",
    "    \n",
    "    # Fill in the numbers\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if puzzle[i, j] != 0:\n",
    "                ax.text(j + 0.5, i + 0.5, str(puzzle[i, j]), \n",
    "                       ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, 9)\n",
    "    ax.set_ylim(0, 9)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'Train #{train_idx}', fontsize=10)\n",
    "\n",
    "# Plot validation puzzles\n",
    "for idx, val_idx in enumerate(val_indices):\n",
    "    row = (idx // 5) + 2  # Start from row 2\n",
    "    col = idx % 5\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    puzzle = val_puzzles[val_idx].cpu().numpy() if torch.is_tensor(val_puzzles[val_idx]) else val_puzzles[val_idx]\n",
    "    \n",
    "    # Fill cells with colors based on numbers\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if puzzle[i, j] != 0:\n",
    "                color = number_colors[puzzle[i, j]]\n",
    "                rect = mpatches.Rectangle((j, i), 1, 1, linewidth=0, \n",
    "                                         edgecolor='none', facecolor=color, alpha=0.6)\n",
    "                ax.add_patch(rect)\n",
    "    \n",
    "    # Draw the grid\n",
    "    for i in range(10):\n",
    "        linewidth = 2 if i % 3 == 0 else 0.5\n",
    "        ax.axhline(i, color='black', linewidth=linewidth)\n",
    "        ax.axvline(i, color='black', linewidth=linewidth)\n",
    "    \n",
    "    # Fill in the numbers\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if puzzle[i, j] != 0:\n",
    "                ax.text(j + 0.5, i + 0.5, str(puzzle[i, j]), \n",
    "                       ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(0, 9)\n",
    "    ax.set_ylim(0, 9)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'Val #{val_idx}', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_positive_losses = []\n",
    "epoch_negative_losses = []\n",
    "val_epoch_losses = []\n",
    "val_epoch_positive_losses = []\n",
    "val_epoch_negative_losses = []\n",
    "validation_epochs = []  # Track which epochs we validated on\n",
    "train_accuracies = []  # Track training accuracies\n",
    "val_accuracies = []  # Track validation accuracies\n",
    "\n",
    "# Checkpoint loading\n",
    "start_epoch = 0\n",
    "if LOAD_CHECKPOINT and os.path.exists(LOAD_CHECKPOINT):\n",
    "    print(f\"Loading checkpoint from {LOAD_CHECKPOINT}\")\n",
    "    checkpoint = torch.load(LOAD_CHECKPOINT, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epoch_losses = checkpoint.get('epoch_losses', [])\n",
    "    epoch_positive_losses = checkpoint.get('epoch_positive_losses', [])\n",
    "    epoch_negative_losses = checkpoint.get('epoch_negative_losses', [])\n",
    "    val_epoch_losses = checkpoint.get('val_epoch_losses', [])\n",
    "    val_epoch_positive_losses = checkpoint.get('val_epoch_positive_losses', [])\n",
    "    val_epoch_negative_losses = checkpoint.get('val_epoch_negative_losses', [])\n",
    "    validation_epochs = checkpoint.get('validation_epochs', [])\n",
    "    train_accuracies = checkpoint.get('train_accuracies', [])\n",
    "    val_accuracies = checkpoint.get('val_accuracies', [])\n",
    "    if USE_AMP and scaler is not None:\n",
    "        scaler.load_state_dict(checkpoint.get('scaler_state_dict', {}))\n",
    "    \n",
    "    # Load hyperparameters from checkpoint\n",
    "    loaded_hp = checkpoint.get('hyperparameters', {})\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "    print(f\"Loaded hyperparameters: {loaded_hp}\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_positive_loss = 0.0\n",
    "    epoch_negative_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Loop over batches\n",
    "    for i in range(0, len(target), BATCH_SIZE):\n",
    "        # Get batch and ensure it's on the correct device\n",
    "        batch_target = target[i:i+BATCH_SIZE].long().to(device)\n",
    "        batch_position = position[i:i+BATCH_SIZE].long().to(device)\n",
    "        batch_puzzles = puzzles[i:i+BATCH_SIZE].long().to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training with autocast\n",
    "        if USE_AMP:\n",
    "            with torch.autocast(device_type=device.type, dtype=amp_dtype):\n",
    "                # Compute loss\n",
    "                loss, negative_loss, positive_loss, accuracy = model.loss(batch_target, batch_position, batch_puzzles)\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Update weights with gradient unscaling\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Standard training without mixed precision\n",
    "            loss, negative_loss, positive_loss, accuracy = model.loss(batch_target, batch_position, batch_puzzles)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Track loss and accuracy\n",
    "        batch_size = batch_puzzles.shape[0]\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_positive_loss += positive_loss.item()\n",
    "        epoch_negative_loss += negative_loss.item()\n",
    "        epoch_correct += (accuracy * batch_size).item()\n",
    "        epoch_total += batch_size\n",
    "        num_batches += 1\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    avg_positive_loss = epoch_positive_loss / num_batches\n",
    "    avg_negative_loss = epoch_negative_loss / num_batches\n",
    "    train_accuracy = epoch_correct / epoch_total\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_positive_losses.append(avg_positive_loss)\n",
    "    epoch_negative_losses.append(avg_negative_loss)\n",
    "    print(f\"\\tEpoch {epoch+1}/{N_EPOCHS}, Average Loss: {avg_loss:.6f} Positive Loss:{avg_positive_loss:.6f} Negative Loss:{avg_negative_loss:.6f} Train Accuracy: {train_accuracy:.6f} ({train_accuracy*100:.2f}%) Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Evaluate on validation set every VALIDATE_PERIOD epochs\n",
    "    if (epoch + 1) % VALIDATE_PERIOD == 0 or (epoch + 1) == N_EPOCHS:\n",
    "        val_start_time = time.time()\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_positive_loss = 0.0\n",
    "        val_negative_loss = 0.0\n",
    "        val_num_batches = 0\n",
    "        \n",
    "        # Store training accuracy for this validation epoch\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Calculate validation accuracy and loss\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            # Also use autocast for validation for consistency\n",
    "            with torch.autocast(device_type=device.type, dtype=amp_dtype, enabled=USE_AMP):\n",
    "                for i in range(0, len(val_target), BATCH_SIZE):\n",
    "                    # Get validation batch and ensure it's on the correct device\n",
    "                    val_batch_target = val_target[i:i+BATCH_SIZE].long().to(device)\n",
    "                    val_batch_position = val_position[i:i+BATCH_SIZE].long().to(device)\n",
    "                    val_batch_puzzles = val_puzzles[i:i+BATCH_SIZE].long().to(device)\n",
    "                    \n",
    "                    # Compute validation loss and accuracy\n",
    "                    loss, negative_loss, positive_loss, accuracy = model.loss(val_batch_target, val_batch_position, val_batch_puzzles)\n",
    "                    \n",
    "                    # Track validation loss\n",
    "                    val_loss += loss.item()\n",
    "                    val_positive_loss += positive_loss.item()\n",
    "                    val_negative_loss += negative_loss.item()\n",
    "                    val_num_batches += 1\n",
    "                    \n",
    "                    # Track accuracy\n",
    "                    batch_size = val_batch_puzzles.shape[0]\n",
    "                    val_correct += (accuracy * batch_size).item()\n",
    "                    val_total += batch_size\n",
    "        \n",
    "        val_time = time.time() - val_start_time\n",
    "        \n",
    "        # Print validation statistics\n",
    "        avg_val_loss = val_loss / val_num_batches\n",
    "        avg_val_positive_loss = val_positive_loss / val_num_batches\n",
    "        avg_val_negative_loss = val_negative_loss / val_num_batches\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_epoch_losses.append(avg_val_loss)\n",
    "        val_epoch_positive_losses.append(avg_val_positive_loss)\n",
    "        val_epoch_negative_losses.append(avg_val_negative_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        validation_epochs.append(epoch + 1)\n",
    "        print(f\"\\t✓ Validation Loss: {avg_val_loss:.6f} Positive Loss:{avg_val_positive_loss:.6f} Negative Loss:{avg_val_negative_loss:.6f}\")\n",
    "        print(f\"\\t✓ Val Accuracy: {val_accuracy:.6f} ({val_accuracy*100:.2f}%) Inference Time: {val_time:.2f}s\")\n",
    "    \n",
    "    # Save checkpoint every CHECKPOINT_PERIOD epochs\n",
    "    if SAVE_CHECKPOINT and (epoch + 1) % CHECKPOINT_PERIOD == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch_losses': epoch_losses,\n",
    "            'epoch_positive_losses': epoch_positive_losses,\n",
    "            'epoch_negative_losses': epoch_negative_losses,\n",
    "            'val_epoch_losses': val_epoch_losses,\n",
    "            'val_epoch_positive_losses': val_epoch_positive_losses,\n",
    "            'val_epoch_negative_losses': val_epoch_negative_losses,\n",
    "            'validation_epochs': validation_epochs,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'hyperparameters': {\n",
    "                'N_EPOCHS': N_EPOCHS,\n",
    "                'LEARNING_RATE': LEARNING_RATE,\n",
    "                'ATTENTION_DIM': ATTENTION_DIM,\n",
    "                'N_HEADS': N_HEADS,\n",
    "                'EMBEDDING_DIM': EMBEDDING_DIM,\n",
    "                'TRAIN_PUZZLES': TRAIN_PUZZLES,\n",
    "                'VAL_PUZZLES': VAL_PUZZLES,\n",
    "                'BATCH_SIZE': BATCH_SIZE,\n",
    "                'SAMPLES_PER_PUZZLE': SAMPLES_PER_PUZZLE,\n",
    "                'NEGATIVE_SAMPLES_SIZE': NEGATIVE_SAMPLES_SIZE,\n",
    "                'USE_NEGATIVE_SAMPLES': USE_NEGATIVE_SAMPLES,\n",
    "            }\n",
    "        }\n",
    "        if USE_AMP and scaler is not None:\n",
    "            checkpoint['scaler_state_dict'] = scaler.state_dict()\n",
    "        \n",
    "        checkpoint_path = get_checkpoint_filename(epoch + 1)\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"\\t💾 Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Save final checkpoint\n",
    "if SAVE_CHECKPOINT:\n",
    "    checkpoint = {\n",
    "        'epoch': N_EPOCHS - 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch_losses': epoch_losses,\n",
    "        'epoch_positive_losses': epoch_positive_losses,\n",
    "        'epoch_negative_losses': epoch_negative_losses,\n",
    "        'val_epoch_losses': val_epoch_losses,\n",
    "        'val_epoch_positive_losses': val_epoch_positive_losses,\n",
    "        'val_epoch_negative_losses': val_epoch_negative_losses,\n",
    "        'validation_epochs': validation_epochs,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'hyperparameters': {\n",
    "            'N_EPOCHS': N_EPOCHS,\n",
    "            'LEARNING_RATE': LEARNING_RATE,\n",
    "            'ATTENTION_DIM': ATTENTION_DIM,\n",
    "            'N_HEADS': N_HEADS,\n",
    "            'EMBEDDING_DIM': EMBEDDING_DIM,\n",
    "            'TRAIN_PUZZLES': TRAIN_PUZZLES,\n",
    "            'VAL_PUZZLES': VAL_PUZZLES,\n",
    "            'BATCH_SIZE': BATCH_SIZE,\n",
    "            'SAMPLES_PER_PUZZLE': SAMPLES_PER_PUZZLE,\n",
    "            'NEGATIVE_SAMPLES_SIZE': NEGATIVE_SAMPLES_SIZE,\n",
    "            'USE_NEGATIVE_SAMPLES': USE_NEGATIVE_SAMPLES,\n",
    "        }\n",
    "    }\n",
    "    if USE_AMP and scaler is not None:\n",
    "        checkpoint['scaler_state_dict'] = scaler.state_dict()\n",
    "    \n",
    "    checkpoint_path = get_checkpoint_filename()\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"💾 Final checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "# Plot the loss curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(range(1, N_EPOCHS + 1), epoch_losses, marker='o', linestyle='-', linewidth=2, label='Total Loss (Train)')\n",
    "ax1.plot(range(1, N_EPOCHS + 1), epoch_positive_losses, marker='s', linestyle='-', linewidth=2, label='Positive Loss (Train)')\n",
    "ax1.plot(range(1, N_EPOCHS + 1), epoch_negative_losses, marker='^', linestyle='-', linewidth=2, label='Negative Loss (Train)')\n",
    "\n",
    "# Plot validation at the epochs where it was actually run\n",
    "ax1.plot(validation_epochs, val_epoch_losses, marker='o', linestyle='--', linewidth=2, label='Total Loss (Val)')\n",
    "ax1.plot(validation_epochs, val_epoch_positive_losses, marker='s', linestyle='--', linewidth=2, label='Positive Loss (Val)')\n",
    "ax1.plot(validation_epochs, val_epoch_negative_losses, marker='^', linestyle='--', linewidth=2, label='Negative Loss (Val)')\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Average Loss (log scale)')\n",
    "ax1.set_title(f'Training Loss over Epochs (Validation every {VALIDATE_PERIOD} epochs)')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(validation_epochs, train_accuracies, marker='o', linestyle='-', linewidth=2, label='Train Accuracy')\n",
    "ax2.plot(validation_epochs, val_accuracies, marker='s', linestyle='--', linewidth=2, label='Val Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title(f'Training and Validation Accuracy (Validation every {VALIDATE_PERIOD} epochs)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
