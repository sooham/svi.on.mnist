{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f4a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sudoku import SudokuGenerator, Sudoku\n",
    "import math\n",
    "import subprocess\n",
    "import gc\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f0d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Model: hidden_dim=128, num_layers=9, kernel_size=3\n",
      "  Embeddings: use_learned=True, embedding_dim=10\n",
      "  Training: dataset_size=20000, epochs=100, batch_size=1024, lr=0.001\n",
      "  Diffusion: k_max=6\n",
      "  Device: cuda\n",
      "  Wandb: enabled=True, project=sudoku-diffusion\n",
      "  Checkpointing: dir=./checkpoints, interval=50\n",
      "\n",
      "âš ï¸  Memory optimizations applied:\n",
      "  - Reduced BATCH_SIZE to 1024 (from 1024)\n",
      "  - Reduced K_MAX to 6 (from 10)\n",
      "  - Reduced DATASET_SIZE to 20000 (from 10000)\n",
      "  - Added memory cleanup in training loop\n",
      "\n",
      "âš¡ Performance optimizations enabled:\n",
      "  - torch.compile() for JIT compilation (2-3x speedup)\n",
      "  - Mixed precision training (AMP) (1.5-2x speedup)\n",
      "  - Fused AdamW optimizer\n",
      "  - Optimized compute_loss() (removed unnecessary clones/ops)\n",
      "  - Expected combined speedup: 3-6x faster training\n",
      "\n",
      "ðŸ’¡ If you still get OOM errors, restart the kernel first!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "# Modify these parameters to experiment with different model configurations\n",
    "\n",
    "# --- Model Architecture Parameters ---\n",
    "HIDDEN_DIM = 128              # Network width (default: 256, reduced for memory)\n",
    "NUM_LAYERS = 9                # Number of residual conv blocks (default: 6, reduced for memory)\n",
    "KERNEL_SIZE = 3               # Conv kernel size\n",
    "NUM_GROUPS = 8                # GroupNorm groups (must divide HIDDEN_DIM evenly)\n",
    "NUM_TIMESTEPS = 81            # Fixed at 81 for Sudoku (9x9 grid)\n",
    "\n",
    "# --- Embedding Parameters ---\n",
    "USE_LEARNED_EMBEDDINGS = True  # Use learned embeddings from LLM model\n",
    "EMBEDDING_MODEL_PATH = './sudoku2vec_trained_model.pt'  # Path to saved embedding model\n",
    "EMBEDDING_DIM = 10            # Dimension of learned embeddings (from LLM model)\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "DATASET_SIZE = 20000          # Number of diffusion sequences to pre-generate\n",
    "NUM_EPOCHS = 100             # Number of training epochs\n",
    "BATCH_SIZE = 1024              # Batch size (reduced from 1024 for memory)\n",
    "LEARNING_RATE = 1e-3          # Optimizer learning rate\n",
    "WEIGHT_DECAY = 1e-4           # AdamW weight decay for regularization\n",
    "GRAD_CLIP_MAX_NORM = 1.0      # Gradient clipping threshold\n",
    "\n",
    "# --- Logging & Evaluation ---\n",
    "LOG_INTERVAL = 10             # Log metrics every N epochs\n",
    "EVAL_INTERVAL = 50           # Evaluate and sample every N epochs\n",
    "\n",
    "# --- Diffusion Parameters ---\n",
    "K_MAX = 6                     # Maximum number of forward steps for multi-step prediction loss (reduced from 10)\n",
    "\n",
    "# --- Device Configuration ---\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Wandb & Checkpointing Configuration ---\n",
    "USE_WANDB = True              # Enable Weights & Biases logging\n",
    "WANDB_PROJECT = \"sudoku-diffusion\"  # Wandb project name\n",
    "WANDB_ENTITY = None           # Wandb entity (None = default)\n",
    "CHECKPOINT_DIR = \"./checkpoints\"  # Directory to save model checkpoints\n",
    "CHECKPOINT_INTERVAL = 50      # Save checkpoint every N epochs\n",
    "RESUME_FROM_CHECKPOINT = None  # Path to checkpoint to resume from (None = start fresh)\n",
    "\n",
    "\n",
    "# --- Sudoku2Vec ---\n",
    "ATTENTION_DIM = 9\n",
    "N_HEADS = 1\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Model: hidden_dim={HIDDEN_DIM}, num_layers={NUM_LAYERS}, kernel_size={KERNEL_SIZE}\")\n",
    "print(f\"  Embeddings: use_learned={USE_LEARNED_EMBEDDINGS}, embedding_dim={EMBEDDING_DIM}\")\n",
    "print(f\"  Training: dataset_size={DATASET_SIZE}, epochs={NUM_EPOCHS}, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(f\"  Diffusion: k_max={K_MAX}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Wandb: enabled={USE_WANDB}, project={WANDB_PROJECT}\")\n",
    "print(f\"  Checkpointing: dir={CHECKPOINT_DIR}, interval={CHECKPOINT_INTERVAL}\")\n",
    "print(\"\\nâš ï¸  Memory optimizations applied:\")\n",
    "print(f\"  - Reduced BATCH_SIZE to {BATCH_SIZE} (from 1024)\")\n",
    "print(f\"  - Reduced K_MAX to {K_MAX} (from 10)\")\n",
    "print(f\"  - Reduced DATASET_SIZE to {DATASET_SIZE} (from 10000)\")\n",
    "print(\"  - Added memory cleanup in training loop\")\n",
    "print(\"\\nâš¡ Performance optimizations enabled:\")\n",
    "print(\"  - torch.compile() for JIT compilation (2-3x speedup)\")\n",
    "print(\"  - Mixed precision training (AMP) (1.5-2x speedup)\")\n",
    "print(\"  - Fused AdamW optimizer\")\n",
    "print(\"  - Optimized compute_loss() (removed unnecessary clones/ops)\")\n",
    "print(\"  - Expected combined speedup: 3-6x faster training\")\n",
    "print(\"\\nðŸ’¡ If you still get OOM errors, restart the kernel first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bb31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD EMBEDDING MODEL (from llm_on_sudoku.ipynb)\n",
    "# ============================================================================\n",
    "# We need the Sudoku2Vec class definition to load the trained model\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding on unit circle for 9x9 Sudoku grid\"\"\"\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Create a grid of positions (0-8 for both x and y)\n",
    "        x_coords = torch.arange(0, 9).unsqueeze(0).repeat(9, 1)\n",
    "        y_coords = torch.arange(0, 9).unsqueeze(1).repeat(1, 9)\n",
    "        \n",
    "        # Convert grid positions to linear indices (0-80)\n",
    "        linear_indices = y_coords * 9 + x_coords  # shape: (9, 9)\n",
    "        \n",
    "        # Convert linear indices to angles on unit circle\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (9, 9)\n",
    "        \n",
    "        # Compute x, y coordinates on unit circle\n",
    "        x_circle = torch.cos(angles)\n",
    "        y_circle = torch.sin(angles)\n",
    "        \n",
    "        # Stack and add batch dimension\n",
    "        pos_encoding = torch.stack([x_circle, y_circle], dim=-1).unsqueeze(0)  # shape: (1, 9, 9, 2)\n",
    "        self.register_buffer('pos_encoding', pos_encoding)\n",
    "    \n",
    "    def get_embedding_for_position(self, pos):\n",
    "        # input (batch, 2) where pos[:, 0] is x and pos[:, 1] is y\n",
    "        linear_indices = pos[:, 1] * 9 + pos[:, 0]  # shape: (batch,)\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (batch,)\n",
    "        x_circle = torch.cos(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        y_circle = torch.sin(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        return torch.cat([x_circle, y_circle], dim=1)  # shape: (batch, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is a (batch, 9, 9, embedding_dim) grid\n",
    "        # output (batch, 9, 9, embedding_dim + 2) grid by adding pos_encoding to x\n",
    "        batch_size = x.shape[0]\n",
    "        pos_expanded = self.pos_encoding.repeat(batch_size, 1, 1, 1)\n",
    "        return torch.cat([x, pos_expanded], dim=-1)\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "# Helper function to support different mask shapes.\n",
    "# Output shape supports (batch_size, number of heads, seq length, seq length)\n",
    "# If 2D: broadcasted over batch size and number of heads\n",
    "# If 3D: broadcasted over number of heads\n",
    "# If 4D: leave as is\n",
    "def expand_mask(mask):\n",
    "    assert mask.ndim >= 2, \"Mask must be at least 2-dimensional with seq_length x seq_length\"\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    while mask.ndim < 4:\n",
    "        mask = mask.unsqueeze(0)\n",
    "    return mask\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # stack all weight matrices 1...h together for efficiency\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, input_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        if mask is not None:\n",
    "            mask = expand_mask(mask)\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # seperate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
    "        qkv = qkv.permute(0,2,1,3) # [batch, head, seqlen, dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0,2,1,3) # [batch, seqlen, head, dims]\n",
    "        values = values.reshape(batch_size, seq_length, self.embed_dim)\n",
    "        o = self.o_proj(values) # [batch, seq_length, 81]\n",
    "\n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o\n",
    "\n",
    "class Sudoku2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, attention_dim=ATTENTION_DIM, num_heads=N_HEADS, device='cpu'):\n",
    "        super(Sudoku2Vec, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.pe = PositionalEncoding()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim) # this will provide the key queries and values\n",
    "        self.total_dim = self.embedding_dim + 2\n",
    "\n",
    "        self.mha = MultiheadAttention(\n",
    "            input_dim=self.total_dim,\n",
    "            embed_dim=attention_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Move model to device\n",
    "        self.to(device)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        \"\"\"\n",
    "        Returns the learned token embeddings.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Embedding weight matrix of shape [vocab_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        return self.embed.weight.detach()\n",
    "    \n",
    "    def get_embedding_for_token(self, token):\n",
    "        \"\"\"\n",
    "        Get the embedding vector for a specific token.\n",
    "        \n",
    "        Args:\n",
    "            token: Integer token ID or tensor of token IDs\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Embedding vector(s) for the given token(s)\n",
    "        \"\"\"\n",
    "        if isinstance(token, int):\n",
    "            token = torch.tensor([token], device=self.device)\n",
    "        elif not isinstance(token, torch.Tensor):\n",
    "            token = torch.tensor(token, device=self.device)\n",
    "        return self.embed(token).detach()\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the model in a portable format that can be easily loaded.\n",
    "        This saves the model architecture and weights in a single file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path where to save the model (should end with .pt or .pth)\n",
    "        \"\"\"\n",
    "        save_dict = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_config': {\n",
    "                'vocab_size': self.embed.num_embeddings,\n",
    "                'embedding_dim': self.embedding_dim,\n",
    "                'attention_dim': self.mha.embed_dim,\n",
    "                'num_heads': self.num_heads,\n",
    "            },\n",
    "            'model_class': 'Sudoku2Vec',\n",
    "        }\n",
    "        torch.save(save_dict, filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath, device='cpu'):\n",
    "        \"\"\"\n",
    "        Load a saved Sudoku2Vec model from file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the saved model file\n",
    "            device: Device to load the model on ('cpu', 'cuda', 'mps')\n",
    "            \n",
    "        Returns:\n",
    "            Sudoku2Vec: Loaded model instance\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        \n",
    "        # Extract configuration\n",
    "        config = checkpoint['model_config']\n",
    "        \n",
    "        # Create model instance\n",
    "        model = cls(\n",
    "            vocab_size=config['vocab_size'],\n",
    "            embedding_dim=config['embedding_dim'],\n",
    "            attention_dim=config['attention_dim'],\n",
    "            num_heads=config['num_heads'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()  # Set to evaluation mode by default\n",
    "        \n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        print(f\"Configuration: vocab_size={config['vocab_size']}, \"\n",
    "              f\"embedding_dim={config['embedding_dim']}, \"\n",
    "              f\"attention_dim={config['attention_dim']}, \"\n",
    "              f\"num_heads={config['num_heads']}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def forward(self, target, position, sudoku_grid, mask=True):\n",
    "        # target - the token in the target blank space we try to predict shape [batch] i.e [0, 3, 3, 5, 1, ...]\n",
    "        # position - the (x, y) position of the target shape [batch, 2] - [[1, 1], [0, 3], [7,7], ...]\n",
    "        # sudoku_grid - the sudoku grid for the problem with target we want to predict shape [batch, 9, 9]\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        target_token_embeddings = self.embed(target) # shape [batch, embedding_dim]\n",
    "        target_position_vectors = self.pe.get_embedding_for_position(position) # [batch, 2]\n",
    "        target_token_with_position = torch.cat([target_token_embeddings, target_position_vectors], dim=-1)  # shape [batch, total_dim]\n",
    "\n",
    "        # mask the target in the grid\n",
    "        sudoku_grid_masked = sudoku_grid\n",
    "        if mask:\n",
    "            batch_indices = torch.arange(sudoku_grid.shape[0], device=self.device)\n",
    "            sudoku_grid_masked = sudoku_grid.clone()\n",
    "            sudoku_grid_masked[batch_indices, position[:, 1], position[:, 0]] = 0 # 0 is a mask token aka blank\n",
    "        \n",
    "        masked_sudoku_grid_embeddings = self.embed(sudoku_grid_masked)\n",
    "        masked_sudoku_grid_with_position = self.pe(masked_sudoku_grid_embeddings) # shape [batch, 9, 9, total_dim]\n",
    "        # Reshape grid to sequence: [batch, 81, total_dim]\n",
    "        masked_grid_seq = masked_sudoku_grid_with_position.view(batch_size, 81, self.total_dim)\n",
    "\n",
    "        grid_seq_embeddings = self.embed(sudoku_grid)\n",
    "        grid_seq_embeddings = grid_seq_embeddings.view(batch_size, 81, self.embedding_dim) \n",
    "        \n",
    "        # Query from target token: [batch, 1, total_dim]\n",
    "        # query = target_token_with_position.unsqueeze(1)\n",
    "\n",
    "        output, attention = self.mha(masked_grid_seq, return_attention=True)\n",
    "        # output is shape [batch, 81, total_dim]\n",
    "        \n",
    "        return output, attention, target_token_with_position, grid_seq_embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592c8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDiffusionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for pre-generated diffusion sequences.\n",
    "    \n",
    "    Each item is a diffusion sequence of shape (82, 9, 9) where:\n",
    "    - Index 0: completely masked grid (all zeros)\n",
    "    - Index 81: completely solved grid\n",
    "    - Indices 1-80: intermediate states with progressively more cells revealed\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences: Tensor of shape (dataset_size, 82, 9, 9) containing diffusion sequences\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "\n",
    "class SudokuDiffusionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Diffusion model for Sudoku puzzles inspired by DDPM.\n",
    "    \n",
    "    Forward process: Progressively mask cells from a complete sudoku (T=81) to empty grid (T=0)\n",
    "    Reverse process: Learn to predict which cells to reveal to go from T to T+1\n",
    "    \n",
    "    The model learns to reverse the masking process, predicting which cell should be revealed\n",
    "    at each timestep given the current partially revealed grid.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=256, num_layers=6, kernel_size=3, num_groups=8, \n",
    "                 embedding_layer=None, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.num_timesteps = 81  # 81 cells in a sudoku grid\n",
    "        self.embedding_layer = embedding_layer\n",
    "        \n",
    "        # Determine input channels based on whether we use embeddings\n",
    "        if embedding_layer is not None:\n",
    "            # Using learned embeddings: embedding_dim channels\n",
    "            input_channels = embedding_layer.embedding_dim\n",
    "            self.use_embeddings = True\n",
    "        else:\n",
    "            # Using simple normalization: 1 channel\n",
    "            input_channels = 1\n",
    "            self.use_embeddings = False\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Convolutional layers for processing the sudoku grid\n",
    "        self.conv_in = nn.Conv2d(input_channels, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.GroupNorm(num_groups, hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.GroupNorm(num_groups, hidden_dim),\n",
    "                nn.SiLU()\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output: dual heads for position and value prediction\n",
    "        self.conv_out = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        # Position head: which cell to reveal (81 possibilities)\n",
    "        self.position_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 9 * 9, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 81)  # Logits for 81 cells\n",
    "        )\n",
    "        \n",
    "        # Value head: what value to place (10 classes: 0-9)\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 9 * 9, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 10)  # Logits for 10 classes\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Predict which cell should be revealed next and what value to place.\n",
    "        \n",
    "        Args:\n",
    "            x: (batch, 9, 9) sudoku grids at timestep t (0 = masked, 1-9 = revealed)\n",
    "            t: (batch,) timesteps (0 to 80)\n",
    "            \n",
    "        Returns:\n",
    "            position_logits: (batch, 81) logits for which cell should be revealed next\n",
    "            value_logits: (batch, 10) logits for what value (0-9) to place\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Process input: either use embeddings or simple normalization\n",
    "        if self.use_embeddings:\n",
    "            # Use learned embeddings: (batch, 9, 9) -> (batch, 9, 9, embedding_dim)\n",
    "            x_embedded = self.embedding_layer(x.long())  # (batch, 9, 9, embedding_dim)\n",
    "            x_norm = x_embedded.permute(0, 3, 1, 2)  # (batch, embedding_dim, 9, 9)\n",
    "        else:\n",
    "            # Simple normalization to [-1, 1] range\n",
    "            x_norm = (x / 4.5) - 1.0\n",
    "            x_norm = x_norm.unsqueeze(1)  # (batch, 1, 9, 9)\n",
    "        \n",
    "        # Time embedding\n",
    "        t_norm = t.float().unsqueeze(1) / self.num_timesteps  # (batch, 1)\n",
    "        t_emb = self.time_embed(t_norm)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Process through conv layers\n",
    "        h = self.conv_in(x_norm)  # (batch, hidden_dim, 9, 9)\n",
    "        \n",
    "        # Add time embedding to spatial features\n",
    "        t_emb_spatial = t_emb.view(batch_size, -1, 1, 1).expand(-1, -1, 9, 9)\n",
    "        h = h + t_emb_spatial\n",
    "        \n",
    "        # Apply conv blocks with residual connections\n",
    "        for block in self.conv_blocks:\n",
    "            h = h + block(h)\n",
    "        \n",
    "        # Output processing\n",
    "        h = self.conv_out(h)  # (batch, hidden_dim, 9, 9)\n",
    "        h_flat = h.reshape(batch_size, -1)  # (batch, hidden_dim * 81)\n",
    "        \n",
    "        # Dual predictions\n",
    "        position_logits = self.position_head(h_flat)  # (batch, 81)\n",
    "        value_logits = self.value_head(h_flat)  # (batch, 10)\n",
    "        \n",
    "        return position_logits, value_logits\n",
    "    \n",
    "    def compute_loss(self, sequences, k_max=10):\n",
    "        \"\"\"\n",
    "        Compute the diffusion loss for training using K-step iterative prediction.\n",
    "        \n",
    "        The forward diffusion process (from sudoku.py) goes from empty (T=0) to complete (T=81).\n",
    "        We learn to predict K steps ahead by iteratively applying the model.\n",
    "        \n",
    "        Args:\n",
    "            sequences: (batch, 82, 9, 9) diffusion sequences where:\n",
    "                      - sequences[:, 0] is completely masked (all zeros)\n",
    "                      - sequences[:, 81] is completely solved\n",
    "            k_max: Maximum number of forward steps for multi-step prediction\n",
    "                      \n",
    "        Returns:\n",
    "            loss: scalar combined loss (position + value)\n",
    "            accuracy: prediction accuracy for logging\n",
    "        \"\"\"\n",
    "        batch_size = sequences.shape[0]\n",
    "        \n",
    "        # Sample random starting timestep B from [0, 81-k_max]\n",
    "        max_start = max(1, self.num_timesteps - k_max)\n",
    "        B = torch.randint(0, max_start, (batch_size,), device=self.device)\n",
    "        \n",
    "        # Sample random K from [1, k_max]\n",
    "        K = torch.randint(1, k_max + 1, (batch_size,), device=self.device)\n",
    "        \n",
    "        # Get starting grids at timestep B (remove unnecessary clone)\n",
    "        x_current = sequences[torch.arange(batch_size), B].float()  # (batch, 9, 9)\n",
    "        \n",
    "        # Track losses and accuracies across all K steps\n",
    "        total_position_loss = 0.0\n",
    "        total_value_loss = 0.0\n",
    "        total_position_acc = 0.0\n",
    "        total_value_acc = 0.0\n",
    "        \n",
    "        # Pre-allocate batch_indices outside loop\n",
    "        batch_indices = torch.arange(batch_size, device=self.device)\n",
    "        \n",
    "        # Iteratively predict K steps\n",
    "        for step in range(k_max):\n",
    "            # Current timestep for each batch element\n",
    "            t_current = B + step\n",
    "            \n",
    "            # Only compute loss for elements where step < K[i] and t_current < 81\n",
    "            active_mask = (step < K) & (t_current < self.num_timesteps)\n",
    "            \n",
    "            if not active_mask.any():\n",
    "                break\n",
    "            \n",
    "            # Get target grid at next timestep\n",
    "            t_next = torch.clamp(t_current + 1, max=self.num_timesteps)\n",
    "            x_target = sequences[batch_indices, t_next].float()  # (batch, 9, 9)\n",
    "            \n",
    "            # Find which cell was revealed (difference between current and target)\n",
    "            diff = (x_target != x_current).view(batch_size, 81)  # (batch, 81)\n",
    "            \n",
    "            # Check if there's actually a difference (cell was revealed)\n",
    "            has_diff = diff.any(dim=1)  # (batch,)\n",
    "            active_mask = active_mask & has_diff  # Only process if there's a change\n",
    "            \n",
    "            if not active_mask.any():\n",
    "                break\n",
    "            \n",
    "            target_position = diff.float().argmax(dim=1)  # (batch,)\n",
    "            \n",
    "            # Get target values at revealed positions (vectorized for efficiency)\n",
    "            rows = target_position // 9\n",
    "            cols = target_position % 9\n",
    "            target_values = x_target[batch_indices, rows, cols].long()\n",
    "            \n",
    "            # Predict position and value\n",
    "            position_logits, value_logits = self.forward(x_current, t_current)  # (batch, 81), (batch, 10)\n",
    "            \n",
    "            # Mask out already revealed cells in position prediction (in-place operation)\n",
    "            already_revealed = (x_current.view(batch_size, 81) != 0)  # (batch, 81)\n",
    "            position_logits.masked_fill_(already_revealed, float('-inf'))\n",
    "            \n",
    "            # Compute losses only for active batch elements\n",
    "            if active_mask.any():\n",
    "                position_loss = F.cross_entropy(position_logits[active_mask], target_position[active_mask], reduction='sum')\n",
    "                value_loss = F.cross_entropy(value_logits[active_mask], target_values[active_mask], reduction='sum')\n",
    "                \n",
    "                # Accumulate losses (keep in computation graph for backprop)\n",
    "                total_position_loss = total_position_loss + position_loss\n",
    "                total_value_loss = total_value_loss + value_loss\n",
    "                \n",
    "                # Compute accuracy for logging\n",
    "                with torch.no_grad():\n",
    "                    pred_position = position_logits[active_mask].argmax(dim=1)\n",
    "                    pred_value = value_logits[active_mask].argmax(dim=1)\n",
    "                    total_position_acc += (pred_position == target_position[active_mask]).float().sum()\n",
    "                    total_value_acc += (pred_value == target_values[active_mask]).float().sum()\n",
    "            \n",
    "            # Update x_current with ground truth for next iteration (remove unnecessary clone)\n",
    "            x_current = x_target\n",
    "        \n",
    "        # Average losses over all active predictions\n",
    "        num_predictions = K.float().sum()\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if num_predictions == 0:\n",
    "            return torch.tensor(0.0, device=self.device), torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        total_position_loss = total_position_loss / num_predictions\n",
    "        total_value_loss = total_value_loss / num_predictions\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = total_position_loss + total_value_loss\n",
    "        \n",
    "        # Average accuracy\n",
    "        accuracy = (total_position_acc + total_value_acc) / (2 * num_predictions)\n",
    "        \n",
    "        return loss, accuracy\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, return_trajectory=False):\n",
    "        \"\"\"\n",
    "        Generate sudoku puzzles by running the reverse diffusion process.\n",
    "        Start from empty grid (T=0) and progressively reveal cells to T=81.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: number of puzzles to generate\n",
    "            return_trajectory: if True, return full trajectory of generation\n",
    "            \n",
    "        Returns:\n",
    "            samples: (batch_size, 9, 9) generated sudoku grids\n",
    "            trajectory: (batch_size, 82, 9, 9) if return_trajectory=True\n",
    "        \"\"\"\n",
    "        # Start from completely masked grid (T=0)\n",
    "        x = torch.zeros(batch_size, 9, 9, device=self.device)\n",
    "        \n",
    "        if return_trajectory:\n",
    "            trajectory = torch.zeros(batch_size, 82, 9, 9, device=self.device)\n",
    "            trajectory[:, 0] = x\n",
    "        \n",
    "        # Progressively reveal cells using model predictions\n",
    "        for t in tqdm(range(self.num_timesteps), desc='Sampling'):\n",
    "            t_batch = torch.full((batch_size,), t, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            # Predict position and value\n",
    "            position_logits, value_logits = self.forward(x, t_batch)\n",
    "            \n",
    "            # Mask out already revealed cells\n",
    "            already_revealed = (x.view(batch_size, 81) != 0)\n",
    "            position_logits = position_logits.masked_fill(already_revealed, float('-inf'))\n",
    "            \n",
    "            # Sample or take argmax for position\n",
    "            position_probs = F.softmax(position_logits, dim=-1)\n",
    "            cell_idx = torch.multinomial(position_probs, 1).squeeze(-1)  # (batch,)\n",
    "            \n",
    "            # Take argmax for value (deterministic)\n",
    "            value_probs = F.softmax(value_logits, dim=-1)\n",
    "            values = torch.argmax(value_probs, dim=-1)  # (batch,)\n",
    "            \n",
    "            # Update grid with predicted values\n",
    "            for b in range(batch_size):\n",
    "                idx = cell_idx[b].item()\n",
    "                row = idx // 9\n",
    "                col = idx % 9\n",
    "                x[b, row, col] = values[b]\n",
    "            \n",
    "            if return_trajectory:\n",
    "                trajectory[:, t + 1] = x\n",
    "        \n",
    "        if return_trajectory:\n",
    "            return x.long(), trajectory.long()\n",
    "        return x.long()\n",
    "\n",
    "\n",
    "def train_sudoku_diffusion(model, dataset, num_epochs=1000, batch_size=32, lr=1e-4, \n",
    "                           weight_decay=1e-4, grad_clip_max_norm=1.0,\n",
    "                           log_interval=10, eval_interval=100, k_max=10, device='cuda',\n",
    "                           use_wandb=False, wandb_project=\"sudoku-diffusion\", wandb_entity=None,\n",
    "                           checkpoint_dir=\"./checkpoints\", checkpoint_interval=50, \n",
    "                           resume_from=None):\n",
    "    \"\"\"\n",
    "    Train the sudoku diffusion model with proper logging and performance optimizations.\n",
    "    \n",
    "    Args:\n",
    "        model: SudokuDiffusionModel instance\n",
    "        dataset: SudokuDiffusionDataset instance with pre-generated sequences\n",
    "        num_epochs: number of training epochs\n",
    "        batch_size: batch size for training\n",
    "        lr: learning rate\n",
    "        weight_decay: weight decay for AdamW optimizer\n",
    "        grad_clip_max_norm: max norm for gradient clipping\n",
    "        log_interval: log metrics every N epochs\n",
    "        eval_interval: evaluate and sample every N epochs\n",
    "        k_max: maximum number of forward steps for multi-step prediction\n",
    "        device: device to train on\n",
    "        use_wandb: whether to log to Weights & Biases\n",
    "        wandb_project: wandb project name\n",
    "        wandb_entity: wandb entity (None = default)\n",
    "        checkpoint_dir: directory to save checkpoints\n",
    "        checkpoint_interval: save checkpoint every N epochs\n",
    "        resume_from: path to checkpoint to resume from (None = start fresh)\n",
    "    \"\"\"\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Create DataLoader for batching and shuffling with optimizations\n",
    "    # Note: pin_memory should be False when data is already on GPU\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Keep 0 for GPU tensors\n",
    "        pin_memory=False,  # Data is already on GPU, no need to pin\n",
    "        persistent_workers=False  # No workers, so this doesn't apply\n",
    "    )\n",
    "    \n",
    "    # Use fused optimizer for faster updates (requires CUDA)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "        weight_decay=weight_decay,\n",
    "        fused=True if device == 'cuda' else False\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Initialize GradScaler for mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler() if device == 'cuda' else None\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    # Starting epoch\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Resume from checkpoint if specified\n",
    "    if resume_from is not None and os.path.exists(resume_from):\n",
    "        print(f\"Loading checkpoint from {resume_from}...\")\n",
    "        checkpoint = torch.load(resume_from, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        if scaler is not None and 'scaler_state_dict' in checkpoint:\n",
    "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        epoch_losses = checkpoint.get('epoch_losses', [])\n",
    "        epoch_accuracies = checkpoint.get('epoch_accuracies', [])\n",
    "        print(f\"âœ“ Resumed from epoch {start_epoch}\")\n",
    "        print(f\"  Previous best loss: {min(epoch_losses) if epoch_losses else 'N/A'}\")\n",
    "    \n",
    "    # Initialize wandb\n",
    "    if use_wandb:\n",
    "        wandb_config = {\n",
    "            \"hidden_dim\": model.conv_in.out_channels,\n",
    "            \"num_layers\": len(model.conv_blocks),\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"k_max\": k_max,\n",
    "            \"dataset_size\": len(dataset),\n",
    "        }\n",
    "        if start_epoch == 0:\n",
    "            wandb.init(project=wandb_project, entity=wandb_entity, config=wandb_config)\n",
    "        else:\n",
    "            # Resume wandb run if checkpoint has run_id\n",
    "            run_id = checkpoint.get('wandb_run_id', None)\n",
    "            wandb.init(project=wandb_project, entity=wandb_entity, config=wandb_config, \n",
    "                      id=run_id, resume=\"allow\")\n",
    "        print(f\"âœ“ Wandb initialized: {wandb.run.name}\")\n",
    "    \n",
    "    model.train()\n",
    "    if start_epoch == 0:\n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    else:\n",
    "        print(f\"Resuming training from epoch {start_epoch} to {num_epochs}...\")\n",
    "    print(f\"Dataset size: {len(dataset)}, Batch size: {batch_size}, Batches per epoch: {len(dataloader)}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Using mixed precision: {scaler is not None}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Iterate through batches in the dataset\n",
    "        for batch_sequences in dataloader:\n",
    "            # Mixed precision training\n",
    "            if scaler is not None:\n",
    "                # Forward pass with autocast\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss, accuracy = model.compute_loss(batch_sequences, k_max=k_max)\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard training (CPU or non-CUDA)\n",
    "                loss, accuracy = model.compute_loss(batch_sequences, k_max=k_max)\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Average metrics over all batches in the epoch\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        avg_epoch_acc = epoch_acc / num_batches\n",
    "        \n",
    "        # Record metrics\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        epoch_accuracies.append(avg_epoch_acc)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to wandb\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train/loss\": avg_epoch_loss,\n",
    "                \"train/accuracy\": avg_epoch_acc,\n",
    "                \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
    "            })\n",
    "        \n",
    "        # Logging\n",
    "        if (epoch + 1) % log_interval == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Epoch {epoch + 1:4d}/{num_epochs} | \"\n",
    "                  f\"Loss: {avg_epoch_loss:.4f} | \"\n",
    "                  f\"Acc: {avg_epoch_acc:.4f} | \"\n",
    "                  f\"LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Evaluation and sampling\n",
    "        if (epoch + 1) % eval_interval == 0:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Evaluation at epoch {epoch + 1}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Generate a sample\n",
    "                sample = model.sample(batch_size=1)\n",
    "                print(\"\\nGenerated Sudoku:\")\n",
    "                print(sample[0].cpu().numpy())\n",
    "                \n",
    "                # Check if valid\n",
    "                sudoku_obj = Sudoku(sample[0].cpu().numpy(), backend='numpy')\n",
    "                is_valid = sudoku_obj.is_valid()\n",
    "                print(f\"\\nIs valid: {is_valid}\")\n",
    "                \n",
    "                # Log to wandb\n",
    "                if use_wandb:\n",
    "                    wandb.log({\n",
    "                        \"eval/is_valid\": int(is_valid),\n",
    "                        \"eval/sample\": wandb.Table(\n",
    "                            data=[[str(sample[0].cpu().numpy())]], \n",
    "                            columns=[\"sudoku_grid\"]\n",
    "                        )\n",
    "                    })\n",
    "            \n",
    "            model.train()\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % checkpoint_interval == 0 or (epoch + 1) == num_epochs:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pt\")\n",
    "            checkpoint_data = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'epoch_losses': epoch_losses,\n",
    "                'epoch_accuracies': epoch_accuracies,\n",
    "                'config': {\n",
    "                    'batch_size': batch_size,\n",
    "                    'learning_rate': lr,\n",
    "                    'weight_decay': weight_decay,\n",
    "                    'k_max': k_max,\n",
    "                }\n",
    "            }\n",
    "            if scaler is not None:\n",
    "                checkpoint_data['scaler_state_dict'] = scaler.state_dict()\n",
    "            if use_wandb:\n",
    "                checkpoint_data['wandb_run_id'] = wandb.run.id\n",
    "            \n",
    "            torch.save(checkpoint_data, checkpoint_path)\n",
    "            print(f\"âœ“ Checkpoint saved: {checkpoint_path}\")\n",
    "            \n",
    "            # Also save as \"latest\" for easy resumption\n",
    "            latest_path = os.path.join(checkpoint_dir, \"checkpoint_latest.pt\")\n",
    "            torch.save(checkpoint_data, latest_path)\n",
    "            print(f\"âœ“ Latest checkpoint updated: {latest_path}\")\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    \n",
    "    # Finish wandb run\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "        print(\"âœ“ Wandb run finished\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(epoch_losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(epoch_accuracies)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, epoch_losses, epoch_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c719fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Information:\n",
      "  Device: NVIDIA RTX A4000\n",
      "  Total Memory: 15.63 GB\n",
      "\n",
      "Initial GPU Memory Usage:\n",
      "  Allocated: 0.52 GB\n",
      "  Cached: 0.53 GB\n",
      "\n",
      "âš ï¸  Clearing GPU memory...\n",
      "\n",
      "After clearing:\n",
      "  Allocated: 0.49 GB\n",
      "  Cached: 0.50 GB\n",
      "  Free: 15.13 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU information and clear memory\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Information:\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    print(f\"\\nInitial GPU Memory Usage:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Aggressively clear GPU memory\n",
    "    print(\"\\nâš ï¸  Clearing GPU memory...\")\n",
    "    \n",
    "    # Delete all variables in the current namespace that might hold GPU tensors\n",
    "    if 'model' in dir():\n",
    "        del model\n",
    "    if 'generator' in dir():\n",
    "        del generator\n",
    "    if 'sequences' in dir():\n",
    "        del sequences\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear PyTorch cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Reset peak memory stats\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.reset_accumulated_memory_stats()\n",
    "    \n",
    "    print(f\"\\nAfter clearing:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # If still not enough memory, suggest kernel restart\n",
    "    free_memory = (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3\n",
    "    if free_memory < 1.0:\n",
    "        print(\"\\nâš ï¸  WARNING: Very little GPU memory available!\")\n",
    "        print(\"   Consider: Kernel -> Restart Kernel to fully clear GPU memory\")\n",
    "else:\n",
    "    print(\"CUDA not available, will use CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c4f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GPU Memory before setup:\n",
      "  Allocated: 0.49 GB\n",
      "  Reserved: 0.50 GB\n",
      "  Free: 15.13 GB\n",
      "\n",
      "============================================================\n",
      "Loading learned embeddings from LLM model...\n",
      "============================================================\n",
      "Model loaded from ./sudoku2vec_trained_model.pt\n",
      "Configuration: vocab_size=10, embedding_dim=10, attention_dim=9, num_heads=1\n",
      "âœ“ Successfully loaded embedding layer with 10 tokens\n",
      "  Embedding dimension: 10\n",
      "\n",
      "âœ“ Embedding layer ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: LOAD EMBEDDING MODEL\n",
    "# ============================================================================\n",
    "# Run this cell once per session to load the pre-trained Sudoku2Vec embeddings.\n",
    "# This is fast (~1 second) and only needs to run once.\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Clear GPU memory if using CUDA\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\nGPU Memory before setup:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3:.2f} GB\")\n",
    "\n",
    "# Load embedding model if configured\n",
    "embedding_layer = None\n",
    "if USE_LEARNED_EMBEDDINGS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Loading learned embeddings from LLM model...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    try:\n",
    "        sudoku2vec_model = Sudoku2Vec.load_model(EMBEDDING_MODEL_PATH, device=DEVICE)\n",
    "        embedding_layer = sudoku2vec_model.embed\n",
    "        print(f\"âœ“ Successfully loaded embedding layer with {embedding_layer.num_embeddings} tokens\")\n",
    "        print(f\"  Embedding dimension: {embedding_layer.embedding_dim}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âš ï¸  WARNING: Embedding model not found at {EMBEDDING_MODEL_PATH}\")\n",
    "        print(\"   Falling back to simple normalization\")\n",
    "        USE_LEARNED_EMBEDDINGS = False\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  WARNING: Failed to load embedding model: {e}\")\n",
    "        print(\"   Falling back to simple normalization\")\n",
    "        USE_LEARNED_EMBEDDINGS = False\n",
    "else:\n",
    "    print(\"\\nUsing simple normalization (no learned embeddings)\")\n",
    "\n",
    "print(\"\\nâœ“ Embedding layer ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55ecb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Pre-generating training dataset...\n",
      "============================================================\n",
      "âœ“ Found cached dataset at cache/sudoku_diffusion_sequences_20000.pt\n",
      "  Loading from cache...\n",
      "âœ“ Dataset loaded from cache in 0.53 seconds\n",
      "\n",
      "Dataset statistics:\n",
      "  Shape: torch.Size([20000, 82, 9, 9])\n",
      "  Memory: 506.74 MB\n",
      "  Device: cuda:0\n",
      "âœ“ Created SudokuDiffusionDataset with 20000 sequences\n",
      "\n",
      "ðŸ’¡ Dataset is ready! You can now rerun Cells 7 & 8 with different hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: GENERATE TRAINING DATASET\n",
    "# ============================================================================\n",
    "# Run this cell ONCE to generate the training dataset.\n",
    "# This is SLOW (~4 minutes for 20k sequences) but you only need to run it once!\n",
    "# \n",
    "# After running this cell, you can:\n",
    "# - Rerun Cell 7 to try different model architectures\n",
    "# - Rerun Cell 8 to try different training hyperparameters\n",
    "# - All without regenerating this expensive dataset!\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Pre-generating training dataset...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define cache file path\n",
    "import os\n",
    "CACHE_DIR = \"cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "DATASET_CACHE_PATH = os.path.join(CACHE_DIR, f\"sudoku_diffusion_sequences_{DATASET_SIZE}.pt\")\n",
    "\n",
    "# Check if cached dataset exists\n",
    "if os.path.exists(DATASET_CACHE_PATH):\n",
    "    print(f\"âœ“ Found cached dataset at {DATASET_CACHE_PATH}\")\n",
    "    print(f\"  Loading from cache...\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sequences = torch.load(DATASET_CACHE_PATH, map_location=DEVICE)\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"âœ“ Dataset loaded from cache in {load_time:.2f} seconds\")\n",
    "else:\n",
    "    print(f\"No cached dataset found. Generating new dataset...\")\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = SudokuGenerator(backend='torch', device=DEVICE)\n",
    "    \n",
    "    # Generate diffusion sequences\n",
    "    print(f\"Generating {DATASET_SIZE} diffusion sequences...\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sequences = generator.generate_diffusion_sequence(size=DATASET_SIZE)\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"âœ“ Dataset generated in {generation_time:.2f} seconds ({generation_time/DATASET_SIZE*1000:.2f} ms per sequence)\")\n",
    "    \n",
    "    # Save to cache\n",
    "    print(f\"Saving dataset to cache: {DATASET_CACHE_PATH}\")\n",
    "    torch.save(sequences, DATASET_CACHE_PATH)\n",
    "    print(f\"âœ“ Dataset cached successfully\")\n",
    "\n",
    "# Report dataset statistics\n",
    "sequence_shape = sequences.shape\n",
    "memory_mb = sequences.element_size() * sequences.nelement() / (1024 ** 2)\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"  Shape: {sequence_shape}\")\n",
    "print(f\"  Memory: {memory_mb:.2f} MB\")\n",
    "print(f\"  Device: {sequences.device}\")\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "train_dataset = SudokuDiffusionDataset(sequences)\n",
    "print(f\"âœ“ Created SudokuDiffusionDataset with {len(train_dataset)} sequences\")\n",
    "print(f\"\\nðŸ’¡ Dataset is ready! You can now rerun Cells 7 & 8 with different hyperparameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8393681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Initializing Diffusion Model...\n",
      "============================================================\n",
      "âœ“ Model initialized successfully\n",
      "  Total parameters: 5,503,423\n",
      "  Trainable parameters: 5,503,423\n",
      "  Using embeddings: True\n",
      "\n",
      "âš¡ Compiling model with torch.compile for faster training...\n",
      "âœ“ Model compiled successfully\n",
      "\n",
      "GPU Memory after model loading:\n",
      "  Allocated: 0.52 GB\n",
      "  Reserved: 1.01 GB\n",
      "\n",
      "âœ“ Model is ready for training!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: INITIALIZE DIFFUSION MODEL\n",
    "# ============================================================================\n",
    "# Run this cell to create and compile the diffusion model.\n",
    "# This is FAST (~5 seconds) and you can rerun it to experiment with:\n",
    "# - Different model sizes (HIDDEN_DIM, NUM_LAYERS)\n",
    "# - Different architectures (KERNEL_SIZE, NUM_GROUPS)\n",
    "# \n",
    "# The dataset from Cell 6 will be reused!\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Initializing Diffusion Model...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "model = SudokuDiffusionModel(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    num_groups=NUM_GROUPS,\n",
    "    embedding_layer=embedding_layer,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ“ Model initialized successfully\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Using embeddings: {model.use_embeddings}\")\n",
    "\n",
    "# Compile model for faster training (PyTorch 2.0+)\n",
    "if DEVICE == 'cuda':\n",
    "    print(f\"\\nâš¡ Compiling model with torch.compile for faster training...\")\n",
    "    try:\n",
    "        model = torch.compile(model, mode='reduce-overhead')\n",
    "        print(f\"âœ“ Model compiled successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not compile model: {e}\")\n",
    "        print(f\"   Continuing without compilation\")\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    print(f\"\\nGPU Memory after model loading:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "print(f\"\\nâœ“ Model is ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: TRAIN THE MODEL\n",
    "# ============================================================================\n",
    "# Run this cell to train the model with the current hyperparameters.\n",
    "# You can rerun this cell to experiment with different:\n",
    "# - Learning rates (LEARNING_RATE)\n",
    "# - Batch sizes (BATCH_SIZE)\n",
    "# - Training strategies (K_MAX, WEIGHT_DECAY, GRAD_CLIP_MAX_NORM)\n",
    "# - Logging intervals (LOG_INTERVAL, EVAL_INTERVAL)\n",
    "# \n",
    "# The model from Cell 7 and dataset from Cell 6 will be used!\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Starting Training...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "model, losses, accuracies = train_sudoku_diffusion(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    grad_clip_max_norm=GRAD_CLIP_MAX_NORM,\n",
    "    log_interval=LOG_INTERVAL,\n",
    "    eval_interval=EVAL_INTERVAL,\n",
    "    k_max=K_MAX,\n",
    "    device=DEVICE,\n",
    "    use_wandb=USE_WANDB,\n",
    "    wandb_project=WANDB_PROJECT,\n",
    "    wandb_entity=WANDB_ENTITY,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    checkpoint_interval=CHECKPOINT_INTERVAL,\n",
    "    resume_from=RESUME_FROM_CHECKPOINT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREPARING VALIDATION DATASET\n",
      "============================================================\n",
      "Generating 1000 validation diffusion sequences...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m     46\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m val_sequences = \u001b[43mgenerator\u001b[49m.generate_diffusion_sequence(size=SWEEP_EXPERIMENT_CONFIG[\u001b[33m'\u001b[39m\u001b[33mval_size\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     50\u001b[39m generation_time = time.time() - start_time\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Validation dataset generated in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_time/SWEEP_EXPERIMENT_CONFIG[\u001b[33m'\u001b[39m\u001b[33mval_size\u001b[39m\u001b[33m'\u001b[39m]*\u001b[32m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms per sequence)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER SWEEP EXPERIMENT WITH VALIDATION\n",
    "# ============================================================================\n",
    "# This cell runs a self-contained experiment to compare different hyperparameters.\n",
    "# It trains separate models for each combination and logs results to wandb.\n",
    "# Now includes validation set evaluation!\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# Experiment configuration\n",
    "SWEEP_EXPERIMENT_CONFIG = {\n",
    "    'learning_rate': 1e-3,  # Fixed learning rate\n",
    "    'hidden_dims': [8, 16, 32, 64, 128],\n",
    "    'k_maxs': [1, 3, 5, 10],\n",
    "    'num_layers_list': [1, 3, 5, 9, 15],\n",
    "    'num_epochs': 300,  # Number of epochs for the experiment\n",
    "    'batch_size': 2048,\n",
    "    'val_size': 1000,  # NEW: Validation set size\n",
    "    'val_interval': 10,  # NEW: Validate every N epochs\n",
    "    'log_interval': 10,\n",
    "    'use_wandb': True,  # Set to True to log to wandb\n",
    "    'wandb_project': 'sudoku-diffusion-hyperparam-sweep-2',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Generate/Load Validation Dataset\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PREPARING VALIDATION DATASET\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Initialize generator for validation dataset\n",
    "generator = SudokuGenerator(\n",
    "    backend='torch',\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "\n",
    "VAL_DATASET_CACHE_PATH = f'sudoku_diffusion_val_{SWEEP_EXPERIMENT_CONFIG[\"val_size\"]}.pt'\n",
    "\n",
    "if os.path.exists(VAL_DATASET_CACHE_PATH):\n",
    "    print(f\"Loading validation dataset from cache: {VAL_DATASET_CACHE_PATH}\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    val_sequences = torch.load(VAL_DATASET_CACHE_PATH, map_location=DEVICE)\n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"âœ“ Validation dataset loaded from cache in {load_time:.2f} seconds\")\n",
    "else:\n",
    "    print(f\"Generating {SWEEP_EXPERIMENT_CONFIG['val_size']} validation diffusion sequences...\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    val_sequences = generator.generate_diffusion_sequence(size=SWEEP_EXPERIMENT_CONFIG['val_size'])\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    print(f\"âœ“ Validation dataset generated in {generation_time:.2f} seconds ({generation_time/SWEEP_EXPERIMENT_CONFIG['val_size']*1000:.2f} ms per sequence)\")\n",
    "    \n",
    "    # Save to cache\n",
    "    print(f\"Saving validation dataset to cache: {VAL_DATASET_CACHE_PATH}\")\n",
    "    torch.save(val_sequences, VAL_DATASET_CACHE_PATH)\n",
    "    print(f\"âœ“ Validation dataset cached successfully\")\n",
    "\n",
    "# Report validation dataset statistics\n",
    "val_sequence_shape = val_sequences.shape\n",
    "val_memory_mb = val_sequences.element_size() * val_sequences.nelement() / (1024 ** 2)\n",
    "print(f\"\\nValidation dataset statistics:\")\n",
    "print(f\"  Shape: {val_sequence_shape}\")\n",
    "print(f\"  Memory: {val_memory_mb:.2f} MB\")\n",
    "print(f\"  Device: {val_sequences.device}\")\n",
    "\n",
    "# Create validation dataset and dataloader\n",
    "val_dataset = SudokuDiffusionDataset(val_sequences)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=SWEEP_EXPERIMENT_CONFIG['batch_size'],\n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "print(f\"âœ“ Created validation dataloader with {len(val_dataset)} sequences\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Setup Sweep Experiment\n",
    "# ============================================================================\n",
    "\n",
    "# Generate all combinations\n",
    "all_combinations = list(itertools.product(\n",
    "    SWEEP_EXPERIMENT_CONFIG['hidden_dims'],\n",
    "    SWEEP_EXPERIMENT_CONFIG['k_maxs'],\n",
    "    SWEEP_EXPERIMENT_CONFIG['num_layers_list']\n",
    "))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"HYPERPARAMETER SWEEP EXPERIMENT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Learning rate (fixed): {SWEEP_EXPERIMENT_CONFIG['learning_rate']}\")\n",
    "print(f\"Hidden dims: {SWEEP_EXPERIMENT_CONFIG['hidden_dims']}\")\n",
    "print(f\"K_max values: {SWEEP_EXPERIMENT_CONFIG['k_maxs']}\")\n",
    "print(f\"Num layers: {SWEEP_EXPERIMENT_CONFIG['num_layers_list']}\")\n",
    "print(f\"Total combinations: {len(all_combinations)}\")\n",
    "print(f\"Epochs per combination: {SWEEP_EXPERIMENT_CONFIG['num_epochs']}\")\n",
    "print(f\"Batch size: {SWEEP_EXPERIMENT_CONFIG['batch_size']}\")\n",
    "print(f\"Validation size: {SWEEP_EXPERIMENT_CONFIG['val_size']}\")\n",
    "print(f\"Validation interval: {SWEEP_EXPERIMENT_CONFIG['val_interval']}\")\n",
    "print(f\"Wandb enabled: {SWEEP_EXPERIMENT_CONFIG['use_wandb']}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Initialize wandb sweep if enabled\n",
    "if SWEEP_EXPERIMENT_CONFIG['use_wandb']:\n",
    "    import wandb\n",
    "    wandb.init(\n",
    "        project=SWEEP_EXPERIMENT_CONFIG['wandb_project'],\n",
    "        name='hyperparam_sweep_experiment',\n",
    "        config=SWEEP_EXPERIMENT_CONFIG\n",
    "    )\n",
    "\n",
    "# Storage for results\n",
    "sweep_results = {}\n",
    "\n",
    "# Create training DataLoader\n",
    "experiment_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=SWEEP_EXPERIMENT_CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "# Run experiment for each combination\n",
    "for combo_idx, (hidden_dim, k_max, num_layers) in enumerate(all_combinations):\n",
    "    combo_key = f\"hd{hidden_dim}_k{k_max}_nl{num_layers}\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training combination {combo_idx + 1}/{len(all_combinations)}\")\n",
    "    print(f\"  Hidden Dim: {hidden_dim}, K_max: {k_max}, Num Layers: {num_layers}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create a fresh model for this combination\n",
    "    experiment_model = SudokuDiffusionModel(\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        kernel_size=KERNEL_SIZE,\n",
    "        num_groups=NUM_GROUPS,\n",
    "        embedding_layer=embedding_layer,\n",
    "        device=DEVICE\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Compile model if using CUDA\n",
    "    if DEVICE == 'cuda':\n",
    "        try:\n",
    "            experiment_model = torch.compile(experiment_model, mode='reduce-overhead')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        experiment_model.parameters(),\n",
    "        lr=SWEEP_EXPERIMENT_CONFIG['learning_rate'],\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        fused=True if DEVICE == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    # Setup gradient scaler for mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler() if DEVICE == 'cuda' else None\n",
    "    \n",
    "    # Track losses and accuracies for this combination\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    val_epoch_losses = []\n",
    "    val_epoch_accuracies = []\n",
    "    val_epochs = []  # Track which epochs we validated on\n",
    "    \n",
    "    experiment_model.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(SWEEP_EXPERIMENT_CONFIG['num_epochs']):\n",
    "        # ====================================================================\n",
    "        # Training Phase\n",
    "        # ====================================================================\n",
    "        experiment_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_sequences in experiment_dataloader:\n",
    "            # Mixed precision training\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    loss, accuracy = experiment_model.compute_loss(\n",
    "                        batch_sequences, \n",
    "                        k_max=k_max\n",
    "                    )\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(experiment_model.parameters(), max_norm=GRAD_CLIP_MAX_NORM)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss, accuracy = experiment_model.compute_loss(\n",
    "                    batch_sequences, \n",
    "                    k_max=k_max\n",
    "                )\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(experiment_model.parameters(), max_norm=GRAD_CLIP_MAX_NORM)\n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Average training metrics\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "        avg_train_acc = epoch_acc / num_batches\n",
    "        \n",
    "        epoch_losses.append(avg_train_loss)\n",
    "        epoch_accuracies.append(avg_train_acc)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Validation Phase (every val_interval epochs)\n",
    "        # ====================================================================\n",
    "        if (epoch + 1) % SWEEP_EXPERIMENT_CONFIG['val_interval'] == 0 or epoch == 0 or epoch == SWEEP_EXPERIMENT_CONFIG['num_epochs'] - 1:\n",
    "            experiment_model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_acc = 0.0\n",
    "            val_num_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for val_batch_sequences in val_dataloader:\n",
    "                    # Mixed precision for validation too\n",
    "                    if scaler is not None:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            loss, accuracy = experiment_model.compute_loss(\n",
    "                                val_batch_sequences,\n",
    "                                k_max=k_max\n",
    "                            )\n",
    "                    else:\n",
    "                        loss, accuracy = experiment_model.compute_loss(\n",
    "                            val_batch_sequences,\n",
    "                            k_max=k_max\n",
    "                        )\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_acc += accuracy.item()\n",
    "                    val_num_batches += 1\n",
    "            \n",
    "            # Average validation metrics\n",
    "            avg_val_loss = val_loss / val_num_batches\n",
    "            avg_val_acc = val_acc / val_num_batches\n",
    "            \n",
    "            val_epoch_losses.append(avg_val_loss)\n",
    "            val_epoch_accuracies.append(avg_val_acc)\n",
    "            val_epochs.append(epoch + 1)\n",
    "            \n",
    "            # Log to wandb (both train and val)\n",
    "            if SWEEP_EXPERIMENT_CONFIG['use_wandb']:\n",
    "                wandb.log({\n",
    "                    f'{combo_key}/train_loss': avg_train_loss,\n",
    "                    f'{combo_key}/train_accuracy': avg_train_acc,\n",
    "                    f'{combo_key}/val_loss': avg_val_loss,\n",
    "                    f'{combo_key}/val_accuracy': avg_val_acc,\n",
    "                    f'{combo_key}/epoch': epoch + 1,\n",
    "                })\n",
    "            \n",
    "            # Print progress with validation metrics\n",
    "            print(f\"  Epoch {epoch + 1:3d}/{SWEEP_EXPERIMENT_CONFIG['num_epochs']} | \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_acc:.4f}\")\n",
    "        else:\n",
    "            # Log only training metrics when not validating\n",
    "            if SWEEP_EXPERIMENT_CONFIG['use_wandb']:\n",
    "                wandb.log({\n",
    "                    f'{combo_key}/train_loss': avg_train_loss,\n",
    "                    f'{combo_key}/train_accuracy': avg_train_acc,\n",
    "                    f'{combo_key}/epoch': epoch + 1,\n",
    "                })\n",
    "            \n",
    "            # Print progress (training only)\n",
    "            if (epoch + 1) % SWEEP_EXPERIMENT_CONFIG['log_interval'] == 0:\n",
    "                print(f\"  Epoch {epoch + 1:3d}/{SWEEP_EXPERIMENT_CONFIG['num_epochs']} | \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.4f}\")\n",
    "    \n",
    "    # Store results (including validation metrics)\n",
    "    sweep_results[combo_key] = {\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'k_max': k_max,\n",
    "        'num_layers': num_layers,\n",
    "        'train_losses': epoch_losses,\n",
    "        'train_accuracies': epoch_accuracies,\n",
    "        'val_losses': val_epoch_losses,\n",
    "        'val_accuracies': val_epoch_accuracies,\n",
    "        'val_epochs': val_epochs,\n",
    "        'final_train_loss': epoch_losses[-1],\n",
    "        'final_train_accuracy': epoch_accuracies[-1],\n",
    "        'final_val_loss': val_epoch_losses[-1],\n",
    "        'final_val_accuracy': val_epoch_accuracies[-1],\n",
    "        'min_train_loss': min(epoch_losses),\n",
    "        'best_train_epoch': epoch_losses.index(min(epoch_losses)) + 1,\n",
    "        'min_val_loss': min(val_epoch_losses),\n",
    "        'best_val_epoch': val_epochs[val_epoch_losses.index(min(val_epoch_losses))],\n",
    "        'max_val_accuracy': max(val_epoch_accuracies),\n",
    "        'best_val_acc_epoch': val_epochs[val_epoch_accuracies.index(max(val_epoch_accuracies))]\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Completed {combo_key}\")\n",
    "    print(f\"  Final Train Loss: {epoch_losses[-1]:.4f} | Final Val Loss: {val_epoch_losses[-1]:.4f}\")\n",
    "    print(f\"  Best Val Loss: {sweep_results[combo_key]['min_val_loss']:.4f} (epoch {sweep_results[combo_key]['best_val_epoch']})\")\n",
    "    print(f\"  Best Val Accuracy: {sweep_results[combo_key]['max_val_accuracy']:.4f} (epoch {sweep_results[combo_key]['best_val_acc_epoch']})\")\n",
    "    \n",
    "    # Clean up\n",
    "    del experiment_model\n",
    "    del optimizer\n",
    "    if scaler is not None:\n",
    "        del scaler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Close wandb run\n",
    "if SWEEP_EXPERIMENT_CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Print summary with validation metrics\n",
    "print(\"\\nSummary of Results (sorted by validation loss):\")\n",
    "print(f\"{'Config':<30} {'Final Train':<13} {'Final Val':<13} {'Best Val Loss':<15} {'Best Val Acc':<15}\")\n",
    "print(\"-\" * 100)\n",
    "for combo_key in sorted(sweep_results.keys(), key=lambda k: sweep_results[k]['min_val_loss']):\n",
    "    result = sweep_results[combo_key]\n",
    "    config_str = f\"hd={result['hidden_dim']},k={result['k_max']},nl={result['num_layers']}\"\n",
    "    print(f\"{config_str:<30} {result['final_train_loss']:<13.4f} {result['final_val_loss']:<13.4f} \"\n",
    "          f\"{result['min_val_loss']:<15.4f} {result['max_val_accuracy']:<15.4f}\")\n",
    "\n",
    "# Find best configuration based on validation loss\n",
    "best_combo_key = min(sweep_results.keys(), key=lambda k: sweep_results[k]['min_val_loss'])\n",
    "best_result = sweep_results[best_combo_key]\n",
    "\n",
    "# Find best configuration based on validation accuracy\n",
    "best_acc_combo_key = max(sweep_results.keys(), key=lambda k: sweep_results[k]['max_val_accuracy'])\n",
    "best_acc_result = sweep_results[best_acc_combo_key]\n",
    "\n",
    "print(f\"\\nðŸ† Best Configuration (by Validation Loss):\")\n",
    "print(f\"   Hidden Dim: {best_result['hidden_dim']}\")\n",
    "print(f\"   K_max: {best_result['k_max']}\")\n",
    "print(f\"   Num Layers: {best_result['num_layers']}\")\n",
    "print(f\"   Best Val Loss: {best_result['min_val_loss']:.4f} at epoch {best_result['best_val_epoch']}\")\n",
    "print(f\"   Best Val Accuracy: {best_result['max_val_accuracy']:.4f} at epoch {best_result['best_val_acc_epoch']}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Best Configuration (by Validation Accuracy):\")\n",
    "print(f\"   Hidden Dim: {best_acc_result['hidden_dim']}\")\n",
    "print(f\"   K_max: {best_acc_result['k_max']}\")\n",
    "print(f\"   Num Layers: {best_acc_result['num_layers']}\")\n",
    "print(f\"   Best Val Accuracy: {best_acc_result['max_val_accuracy']:.4f} at epoch {best_acc_result['best_val_acc_epoch']}\")\n",
    "print(f\"   Best Val Loss: {best_acc_result['min_val_loss']:.4f} at epoch {best_acc_result['best_val_epoch']}\")\n",
    "\n",
    "print(\"\\nâœ“ Experiment complete! View detailed results in wandb.\")\n",
    "print(f\"\\nðŸ’¡ Primary Recommendation (lowest val loss): Hidden Dim={best_result['hidden_dim']}, K_max={best_result['k_max']}, Num Layers={best_result['num_layers']}\")\n",
    "print(f\"ðŸ’¡ Alternative Recommendation (highest val acc): Hidden Dim={best_acc_result['hidden_dim']}, K_max={best_acc_result['k_max']}, Num Layers={best_acc_result['num_layers']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1926b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
