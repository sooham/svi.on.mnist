{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83f4a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sudoku import SudokuGenerator, Sudoku\n",
    "import math\n",
    "import subprocess\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22f0d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Model: hidden_dim=64, num_layers=9, kernel_size=3\n",
      "  Embeddings: use_learned=True, embedding_dim=15\n",
      "  Training: dataset_size=10000, epochs=1000, batch_size=1024, lr=0.0001\n",
      "  Diffusion: k_max=10\n",
      "  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "# Modify these parameters to experiment with different model configurations\n",
    "\n",
    "# --- Model Architecture Parameters ---\n",
    "HIDDEN_DIM = 64              # Network width (default: 256, reduced for memory)\n",
    "NUM_LAYERS = 9                # Number of residual conv blocks (default: 6, reduced for memory)\n",
    "KERNEL_SIZE = 3               # Conv kernel size\n",
    "NUM_GROUPS = 8                # GroupNorm groups (must divide HIDDEN_DIM evenly)\n",
    "NUM_TIMESTEPS = 81            # Fixed at 81 for Sudoku (9x9 grid)\n",
    "\n",
    "# --- Embedding Parameters ---\n",
    "USE_LEARNED_EMBEDDINGS = True  # Use learned embeddings from LLM model\n",
    "EMBEDDING_MODEL_PATH = './sudoku2vec_trained_model.pt'  # Path to saved embedding model\n",
    "EMBEDDING_DIM = 15            # Dimension of learned embeddings (from LLM model)\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "DATASET_SIZE = 10000          # Number of diffusion sequences to pre-generate\n",
    "NUM_EPOCHS = 1000             # Number of training epochs\n",
    "BATCH_SIZE = 1024             # Batch size (default: 32, reduced for memory)\n",
    "LEARNING_RATE = 1e-4          # Optimizer learning rate\n",
    "WEIGHT_DECAY = 1e-4           # AdamW weight decay for regularization\n",
    "GRAD_CLIP_MAX_NORM = 1.0      # Gradient clipping threshold\n",
    "\n",
    "# --- Logging & Evaluation ---\n",
    "LOG_INTERVAL = 1             # Log metrics every N epochs\n",
    "EVAL_INTERVAL = 15           # Evaluate and sample every N epochs\n",
    "\n",
    "# --- Diffusion Parameters ---\n",
    "K_MAX = 10                   # Maximum number of forward steps for multi-step prediction loss\n",
    "\n",
    "# --- Device Configuration ---\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- Sudoku2Vec ---\n",
    "ATTENTION_DIM = 9\n",
    "N_HEADS = 9\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Model: hidden_dim={HIDDEN_DIM}, num_layers={NUM_LAYERS}, kernel_size={KERNEL_SIZE}\")\n",
    "print(f\"  Embeddings: use_learned={USE_LEARNED_EMBEDDINGS}, embedding_dim={EMBEDDING_DIM}\")\n",
    "print(f\"  Training: dataset_size={DATASET_SIZE}, epochs={NUM_EPOCHS}, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(f\"  Diffusion: k_max={K_MAX}\")\n",
    "print(f\"  Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1bb31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD EMBEDDING MODEL (from llm_on_sudoku.ipynb)\n",
    "# ============================================================================\n",
    "# We need the Sudoku2Vec class definition to load the trained model\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding on unit circle for 9x9 Sudoku grid\"\"\"\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Create a grid of positions (0-8 for both x and y)\n",
    "        x_coords = torch.arange(0, 9).unsqueeze(0).repeat(9, 1)\n",
    "        y_coords = torch.arange(0, 9).unsqueeze(1).repeat(1, 9)\n",
    "        \n",
    "        # Convert grid positions to linear indices (0-80)\n",
    "        linear_indices = y_coords * 9 + x_coords  # shape: (9, 9)\n",
    "        \n",
    "        # Convert linear indices to angles on unit circle\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (9, 9)\n",
    "        \n",
    "        # Compute x, y coordinates on unit circle\n",
    "        x_circle = torch.cos(angles)\n",
    "        y_circle = torch.sin(angles)\n",
    "        \n",
    "        # Stack and add batch dimension\n",
    "        self.pos_encoding = torch.stack([x_circle, y_circle], dim=-1).unsqueeze(0)  # shape: (1, 9, 9, 2)\n",
    "    \n",
    "    def get_embedding_for_position(self, pos):\n",
    "        # input (batch, 2) where pos[:, 0] is x and pos[:, 1] is y\n",
    "        linear_indices = pos[:, 1] * 9 + pos[:, 0]  # shape: (batch,)\n",
    "        angles = 2 * math.pi * linear_indices / 81  # shape: (batch,)\n",
    "        x_circle = torch.cos(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        y_circle = torch.sin(angles).unsqueeze(1)  # shape: (batch, 1)\n",
    "        return torch.cat([x_circle, y_circle], dim=1)  # shape: (batch, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is a (batch, 9, 9, embedding_dim) grid\n",
    "        # output (batch, 9, 9, embedding_dim + 2) grid by adding pos_encoding to x\n",
    "        batch_size = x.shape[0]\n",
    "        pos_expanded = self.pos_encoding.repeat(batch_size, 1, 1, 1)\n",
    "        return torch.cat([x, pos_expanded], dim=-1)\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "# Helper function to support different mask shapes.\n",
    "# Output shape supports (batch_size, number of heads, seq length, seq length)\n",
    "# If 2D: broadcasted over batch size and number of heads\n",
    "# If 3D: broadcasted over number of heads\n",
    "# If 4D: leave as is\n",
    "def expand_mask(mask):\n",
    "    assert mask.ndim >= 2, \"Mask must be at least 2-dimensional with seq_length x seq_length\"\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask.unsqueeze(1)\n",
    "    while mask.ndim < 4:\n",
    "        mask = mask.unsqueeze(0)\n",
    "    return mask\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # stack all weight matrices 1...h together for efficiency\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, input_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        if mask is not None:\n",
    "            mask = expand_mask(mask)\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # seperate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
    "        qkv = qkv.permute(0,2,1,3) # [batch, head, seqlen, dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0,2,1,3) # [batch, seqlen, head, dims]\n",
    "        values = values.reshape(batch_size, seq_length, self.embed_dim)\n",
    "        o = self.o_proj(values) # [batch, seq_length, 81]\n",
    "\n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o\n",
    "\n",
    "class Sudoku2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, attention_dim=ATTENTION_DIM, num_heads=N_HEADS, device='cpu'):\n",
    "        super(Sudoku2Vec, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.pe = PositionalEncoding()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim) # this will provide the key queries and values\n",
    "        self.total_dim = self.embedding_dim + 2\n",
    "\n",
    "        self.mha = MultiheadAttention(\n",
    "            input_dim=self.total_dim,\n",
    "            embed_dim=attention_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Move model to device\n",
    "        self.to(device)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        \"\"\"\n",
    "        Returns the learned token embeddings.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Embedding weight matrix of shape [vocab_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        return self.embed.weight.detach()\n",
    "    \n",
    "    def get_embedding_for_token(self, token):\n",
    "        \"\"\"\n",
    "        Get the embedding vector for a specific token.\n",
    "        \n",
    "        Args:\n",
    "            token: Integer token ID or tensor of token IDs\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Embedding vector(s) for the given token(s)\n",
    "        \"\"\"\n",
    "        if isinstance(token, int):\n",
    "            token = torch.tensor([token], device=self.device)\n",
    "        elif not isinstance(token, torch.Tensor):\n",
    "            token = torch.tensor(token, device=self.device)\n",
    "        return self.embed(token).detach()\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the model in a portable format that can be easily loaded.\n",
    "        This saves the model architecture and weights in a single file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path where to save the model (should end with .pt or .pth)\n",
    "        \"\"\"\n",
    "        save_dict = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_config': {\n",
    "                'vocab_size': self.embed.num_embeddings,\n",
    "                'embedding_dim': self.embedding_dim,\n",
    "                'attention_dim': self.mha.embed_dim,\n",
    "                'num_heads': self.num_heads,\n",
    "            },\n",
    "            'model_class': 'Sudoku2Vec',\n",
    "        }\n",
    "        torch.save(save_dict, filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath, device='cpu'):\n",
    "        \"\"\"\n",
    "        Load a saved Sudoku2Vec model from file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the saved model file\n",
    "            device: Device to load the model on ('cpu', 'cuda', 'mps')\n",
    "            \n",
    "        Returns:\n",
    "            Sudoku2Vec: Loaded model instance\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(filepath, map_location=device)\n",
    "        \n",
    "        # Extract configuration\n",
    "        config = checkpoint['model_config']\n",
    "        \n",
    "        # Create model instance\n",
    "        model = cls(\n",
    "            vocab_size=config['vocab_size'],\n",
    "            embedding_dim=config['embedding_dim'],\n",
    "            attention_dim=config['attention_dim'],\n",
    "            num_heads=config['num_heads'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()  # Set to evaluation mode by default\n",
    "        \n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "        print(f\"Configuration: vocab_size={config['vocab_size']}, \"\n",
    "              f\"embedding_dim={config['embedding_dim']}, \"\n",
    "              f\"attention_dim={config['attention_dim']}, \"\n",
    "              f\"num_heads={config['num_heads']}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def forward(self, target, position, sudoku_grid, mask=True):\n",
    "        # target - the token in the target blank space we try to predict shape [batch] i.e [0, 3, 3, 5, 1, ...]\n",
    "        # position - the (x, y) position of the target shape [batch, 2] - [[1, 1], [0, 3], [7,7], ...]\n",
    "        # sudoku_grid - the sudoku grid for the problem with target we want to predict shape [batch, 9, 9]\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        target_token_embeddings = self.embed(target) # shape [batch, embedding_dim]\n",
    "        target_position_vectors = self.pe.get_embedding_for_position(position) # [batch, 2]\n",
    "        target_token_with_position = torch.cat([target_token_embeddings, target_position_vectors], dim=-1)  # shape [batch, total_dim]\n",
    "\n",
    "        # mask the target in the grid\n",
    "        sudoku_grid_masked = sudoku_grid\n",
    "        if mask:\n",
    "            batch_indices = torch.arange(sudoku_grid.shape[0], device=self.device)\n",
    "            sudoku_grid_masked = sudoku_grid.clone()\n",
    "            sudoku_grid_masked[batch_indices, position[:, 1], position[:, 0]] = 0 # 0 is a mask token aka blank\n",
    "        \n",
    "        masked_sudoku_grid_embeddings = self.embed(sudoku_grid_masked)\n",
    "        masked_sudoku_grid_with_position = self.pe(masked_sudoku_grid_embeddings) # shape [batch, 9, 9, total_dim]\n",
    "        # Reshape grid to sequence: [batch, 81, total_dim]\n",
    "        masked_grid_seq = masked_sudoku_grid_with_position.view(batch_size, 81, self.total_dim)\n",
    "\n",
    "        grid_seq_embeddings = self.embed(sudoku_grid)\n",
    "        grid_seq_embeddings = grid_seq_embeddings.view(batch_size, 81, self.embedding_dim) \n",
    "        \n",
    "        # Query from target token: [batch, 1, total_dim]\n",
    "        # query = target_token_with_position.unsqueeze(1)\n",
    "\n",
    "        output, attention = self.mha(masked_grid_seq, return_attention=True)\n",
    "        # output is shape [batch, 81, total_dim]\n",
    "        \n",
    "        return output, attention, target_token_with_position, grid_seq_embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "592c8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDiffusionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for pre-generated diffusion sequences.\n",
    "    \n",
    "    Each item is a diffusion sequence of shape (82, 9, 9) where:\n",
    "    - Index 0: completely masked grid (all zeros)\n",
    "    - Index 81: completely solved grid\n",
    "    - Indices 1-80: intermediate states with progressively more cells revealed\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences: Tensor of shape (dataset_size, 82, 9, 9) containing diffusion sequences\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "\n",
    "class SudokuDiffusionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Diffusion model for Sudoku puzzles inspired by DDPM.\n",
    "    \n",
    "    Forward process: Progressively mask cells from a complete sudoku (T=81) to empty grid (T=0)\n",
    "    Reverse process: Learn to predict which cells to reveal to go from T to T+1\n",
    "    \n",
    "    The model learns to reverse the masking process, predicting which cell should be revealed\n",
    "    at each timestep given the current partially revealed grid.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=256, num_layers=6, kernel_size=3, num_groups=8, \n",
    "                 embedding_layer=None, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.num_timesteps = 81  # 81 cells in a sudoku grid\n",
    "        self.embedding_layer = embedding_layer\n",
    "        \n",
    "        # Determine input channels based on whether we use embeddings\n",
    "        if embedding_layer is not None:\n",
    "            # Using learned embeddings: embedding_dim channels\n",
    "            input_channels = embedding_layer.embedding_dim\n",
    "            self.use_embeddings = True\n",
    "        else:\n",
    "            # Using simple normalization: 1 channel\n",
    "            input_channels = 1\n",
    "            self.use_embeddings = False\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Convolutional layers for processing the sudoku grid\n",
    "        self.conv_in = nn.Conv2d(input_channels, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.GroupNorm(num_groups, hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.GroupNorm(num_groups, hidden_dim),\n",
    "                nn.SiLU()\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output: dual heads for position and value prediction\n",
    "        self.conv_out = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        # Position head: which cell to reveal (81 possibilities)\n",
    "        self.position_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 9 * 9, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 81)  # Logits for 81 cells\n",
    "        )\n",
    "        \n",
    "        # Value head: what value to place (10 classes: 0-9)\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 9 * 9, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, 10)  # Logits for 10 classes\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Predict which cell should be revealed next and what value to place.\n",
    "        \n",
    "        Args:\n",
    "            x: (batch, 9, 9) sudoku grids at timestep t (0 = masked, 1-9 = revealed)\n",
    "            t: (batch,) timesteps (0 to 80)\n",
    "            \n",
    "        Returns:\n",
    "            position_logits: (batch, 81) logits for which cell should be revealed next\n",
    "            value_logits: (batch, 10) logits for what value (0-9) to place\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Process input: either use embeddings or simple normalization\n",
    "        if self.use_embeddings:\n",
    "            # Use learned embeddings: (batch, 9, 9) -> (batch, 9, 9, embedding_dim)\n",
    "            x_embedded = self.embedding_layer(x.long())  # (batch, 9, 9, embedding_dim)\n",
    "            x_norm = x_embedded.permute(0, 3, 1, 2)  # (batch, embedding_dim, 9, 9)\n",
    "        else:\n",
    "            # Simple normalization to [-1, 1] range\n",
    "            x_norm = (x / 4.5) - 1.0\n",
    "            x_norm = x_norm.unsqueeze(1)  # (batch, 1, 9, 9)\n",
    "        \n",
    "        # Time embedding\n",
    "        t_norm = t.float().unsqueeze(1) / self.num_timesteps  # (batch, 1)\n",
    "        t_emb = self.time_embed(t_norm)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Process through conv layers\n",
    "        h = self.conv_in(x_norm)  # (batch, hidden_dim, 9, 9)\n",
    "        \n",
    "        # Add time embedding to spatial features\n",
    "        t_emb_spatial = t_emb.view(batch_size, -1, 1, 1).expand(-1, -1, 9, 9)\n",
    "        h = h + t_emb_spatial\n",
    "        \n",
    "        # Apply conv blocks with residual connections\n",
    "        for block in self.conv_blocks:\n",
    "            h = h + block(h)\n",
    "        \n",
    "        # Output processing\n",
    "        h = self.conv_out(h)  # (batch, hidden_dim, 9, 9)\n",
    "        h_flat = h.view(batch_size, -1)  # (batch, hidden_dim * 81)\n",
    "        \n",
    "        # Dual predictions\n",
    "        position_logits = self.position_head(h_flat)  # (batch, 81)\n",
    "        value_logits = self.value_head(h_flat)  # (batch, 10)\n",
    "        \n",
    "        return position_logits, value_logits\n",
    "    \n",
    "    def compute_loss(self, sequences, k_max=10):\n",
    "        \"\"\"\n",
    "        Compute the diffusion loss for training using K-step iterative prediction.\n",
    "        \n",
    "        The forward diffusion process (from sudoku.py) goes from empty (T=0) to complete (T=81).\n",
    "        We learn to predict K steps ahead by iteratively applying the model.\n",
    "        \n",
    "        Args:\n",
    "            sequences: (batch, 82, 9, 9) diffusion sequences where:\n",
    "                      - sequences[:, 0] is completely masked (all zeros)\n",
    "                      - sequences[:, 81] is completely solved\n",
    "            k_max: Maximum number of forward steps for multi-step prediction\n",
    "                      \n",
    "        Returns:\n",
    "            loss: scalar combined loss (position + value)\n",
    "            accuracy: prediction accuracy for logging\n",
    "        \"\"\"\n",
    "        batch_size = sequences.shape[0]\n",
    "        \n",
    "        # Sample random starting timestep B from [0, 81-k_max]\n",
    "        max_start = max(1, self.num_timesteps - k_max)\n",
    "        B = torch.randint(0, max_start, (batch_size,), device=self.device)\n",
    "        \n",
    "        # Sample random K from [1, k_max]\n",
    "        K = torch.randint(1, k_max + 1, (batch_size,), device=self.device)\n",
    "        \n",
    "        # Get starting grids at timestep B\n",
    "        x_current = sequences[torch.arange(batch_size), B].float().clone()  # (batch, 9, 9)\n",
    "        \n",
    "        # Track losses and accuracies across all K steps\n",
    "        total_position_loss = 0.0\n",
    "        total_value_loss = 0.0\n",
    "        total_position_acc = 0.0\n",
    "        total_value_acc = 0.0\n",
    "        \n",
    "        # Iteratively predict K steps\n",
    "        for step in range(k_max):\n",
    "            # Current timestep for each batch element\n",
    "            t_current = B + step\n",
    "            \n",
    "            # Only compute loss for elements where step < K[i]\n",
    "            active_mask = (step < K)\n",
    "            \n",
    "            if not active_mask.any():\n",
    "                break\n",
    "            \n",
    "            # Get target grid at next timestep\n",
    "            t_next = t_current + 1\n",
    "            x_target = sequences[torch.arange(batch_size), t_next].float()  # (batch, 9, 9)\n",
    "            \n",
    "            # Find which cell was revealed (difference between current and target)\n",
    "            diff = (x_target != x_current).view(batch_size, 81)  # (batch, 81)\n",
    "            target_position = diff.float().argmax(dim=1)  # (batch,)\n",
    "            \n",
    "            # Get target values at revealed positions\n",
    "            target_values = torch.zeros(batch_size, dtype=torch.long, device=self.device)\n",
    "            for b in range(batch_size):\n",
    "                pos = target_position[b].item()\n",
    "                row, col = pos // 9, pos % 9\n",
    "                target_values[b] = x_target[b, row, col].long()\n",
    "            \n",
    "            # Predict position and value\n",
    "            position_logits, value_logits = self.forward(x_current, t_current)  # (batch, 81), (batch, 10)\n",
    "            \n",
    "            # Mask out already revealed cells in position prediction\n",
    "            already_revealed = (x_current.view(batch_size, 81) != 0)  # (batch, 81)\n",
    "            position_logits_masked = position_logits.masked_fill(already_revealed, float('-inf'))\n",
    "            \n",
    "            # Compute losses only for active batch elements\n",
    "            if active_mask.any():\n",
    "                position_loss = F.cross_entropy(position_logits_masked[active_mask], target_position[active_mask], reduction='sum')\n",
    "                value_loss = F.cross_entropy(value_logits[active_mask], target_values[active_mask], reduction='sum')\n",
    "                \n",
    "                total_position_loss += position_loss\n",
    "                total_value_loss += value_loss\n",
    "                \n",
    "                # Compute accuracy for logging\n",
    "                with torch.no_grad():\n",
    "                    pred_position = position_logits_masked[active_mask].argmax(dim=1)\n",
    "                    pred_value = value_logits[active_mask].argmax(dim=1)\n",
    "                    total_position_acc += (pred_position == target_position[active_mask]).float().sum()\n",
    "                    total_value_acc += (pred_value == target_values[active_mask]).float().sum()\n",
    "            \n",
    "            # Update x_current with predicted values for next iteration\n",
    "            with torch.no_grad():\n",
    "                pred_positions = position_logits_masked.argmax(dim=1)  # (batch,)\n",
    "                pred_values = value_logits.argmax(dim=1)  # (batch,)\n",
    "                \n",
    "                for b in range(batch_size):\n",
    "                    if active_mask[b]:\n",
    "                        pos = pred_positions[b].item()\n",
    "                        row, col = pos // 9, pos % 9\n",
    "                        x_current[b, row, col] = pred_values[b].float()\n",
    "        \n",
    "        # Average losses over all active predictions\n",
    "        num_predictions = K.float().sum()\n",
    "        total_position_loss = total_position_loss / num_predictions\n",
    "        total_value_loss = total_value_loss / num_predictions\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = total_position_loss + total_value_loss\n",
    "        \n",
    "        # Average accuracy\n",
    "        accuracy = (total_position_acc + total_value_acc) / (2 * num_predictions)\n",
    "        \n",
    "        return loss, accuracy\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, return_trajectory=False):\n",
    "        \"\"\"\n",
    "        Generate sudoku puzzles by running the reverse diffusion process.\n",
    "        Start from empty grid (T=0) and progressively reveal cells to T=81.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: number of puzzles to generate\n",
    "            return_trajectory: if True, return full trajectory of generation\n",
    "            \n",
    "        Returns:\n",
    "            samples: (batch_size, 9, 9) generated sudoku grids\n",
    "            trajectory: (batch_size, 82, 9, 9) if return_trajectory=True\n",
    "        \"\"\"\n",
    "        # Start from completely masked grid (T=0)\n",
    "        x = torch.zeros(batch_size, 9, 9, device=self.device)\n",
    "        \n",
    "        if return_trajectory:\n",
    "            trajectory = torch.zeros(batch_size, 82, 9, 9, device=self.device)\n",
    "            trajectory[:, 0] = x\n",
    "        \n",
    "        # Progressively reveal cells using model predictions\n",
    "        for t in tqdm(range(self.num_timesteps), desc='Sampling'):\n",
    "            t_batch = torch.full((batch_size,), t, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            # Predict position and value\n",
    "            position_logits, value_logits = self.forward(x, t_batch)\n",
    "            \n",
    "            # Mask out already revealed cells\n",
    "            already_revealed = (x.view(batch_size, 81) != 0)\n",
    "            position_logits = position_logits.masked_fill(already_revealed, float('-inf'))\n",
    "            \n",
    "            # Sample or take argmax for position\n",
    "            position_probs = F.softmax(position_logits, dim=-1)\n",
    "            cell_idx = torch.multinomial(position_probs, 1).squeeze(-1)  # (batch,)\n",
    "            \n",
    "            # Take argmax for value (deterministic)\n",
    "            value_probs = F.softmax(value_logits, dim=-1)\n",
    "            values = torch.argmax(value_probs, dim=-1)  # (batch,)\n",
    "            \n",
    "            # Update grid with predicted values\n",
    "            for b in range(batch_size):\n",
    "                idx = cell_idx[b].item()\n",
    "                row = idx // 9\n",
    "                col = idx % 9\n",
    "                x[b, row, col] = values[b]\n",
    "            \n",
    "            if return_trajectory:\n",
    "                trajectory[:, t + 1] = x\n",
    "        \n",
    "        if return_trajectory:\n",
    "            return x.long(), trajectory.long()\n",
    "        return x.long()\n",
    "\n",
    "\n",
    "def train_sudoku_diffusion(model, dataset, num_epochs=1000, batch_size=32, lr=1e-4, \n",
    "                           weight_decay=1e-4, grad_clip_max_norm=1.0,\n",
    "                           log_interval=10, eval_interval=100, k_max=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train the sudoku diffusion model with proper logging.\n",
    "    \n",
    "    Args:\n",
    "        model: SudokuDiffusionModel instance\n",
    "        dataset: SudokuDiffusionDataset instance with pre-generated sequences\n",
    "        num_epochs: number of training epochs\n",
    "        batch_size: batch size for training\n",
    "        lr: learning rate\n",
    "        weight_decay: weight decay for AdamW optimizer\n",
    "        grad_clip_max_norm: max norm for gradient clipping\n",
    "        log_interval: log metrics every N epochs\n",
    "        eval_interval: evaluate and sample every N epochs\n",
    "        k_max: maximum number of forward steps for multi-step prediction\n",
    "        device: device to train on\n",
    "    \"\"\"\n",
    "    # Create DataLoader for batching and shuffling\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Keep 0 for GPU tensors\n",
    "        pin_memory=True if device == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    model.train()\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    print(f\"Dataset size: {len(dataset)}, Batch size: {batch_size}, Batches per epoch: {len(dataloader)}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Iterate through batches in the dataset\n",
    "        for batch_sequences in dataloader:\n",
    "            # Compute loss for this batch\n",
    "            loss, accuracy = model.compute_loss(batch_sequences, k_max=k_max)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Average metrics over all batches in the epoch\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        avg_epoch_acc = epoch_acc / num_batches\n",
    "        \n",
    "        # Record metrics\n",
    "        epoch_losses.append(avg_epoch_loss)\n",
    "        epoch_accuracies.append(avg_epoch_acc)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Logging\n",
    "        if (epoch + 1) % log_interval == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Epoch {epoch + 1:4d}/{num_epochs} | \"\n",
    "                  f\"Loss: {avg_epoch_loss:.4f} | \"\n",
    "                  f\"Acc: {avg_epoch_acc:.4f} | \"\n",
    "                  f\"LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Evaluation and sampling\n",
    "        if (epoch + 1) % eval_interval == 0:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Evaluation at epoch {epoch + 1}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Generate a sample\n",
    "                sample = model.sample(batch_size=1)\n",
    "                print(\"\\nGenerated Sudoku:\")\n",
    "                print(sample[0].cpu().numpy())\n",
    "                \n",
    "                # Check if valid\n",
    "                sudoku_obj = Sudoku(sample[0].cpu().numpy(), backend='numpy')\n",
    "                is_valid = sudoku_obj.is_valid()\n",
    "                print(f\"\\nIs valid: {is_valid}\")\n",
    "            \n",
    "            model.train()\n",
    "            print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(epoch_losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(epoch_accuracies)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, epoch_losses, epoch_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c719fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Information:\n",
      "  Device: NVIDIA RTX A4000\n",
      "  Total Memory: 15.63 GB\n",
      "\n",
      "Initial GPU Memory Usage:\n",
      "  Allocated: 0.11 GB\n",
      "  Cached: 1.44 GB\n",
      "\n",
      "⚠️  Clearing GPU memory...\n",
      "\n",
      "After clearing:\n",
      "  Allocated: 0.08 GB\n",
      "  Cached: 0.12 GB\n",
      "  Free: 15.50 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU information and clear memory\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Information:\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    print(f\"\\nInitial GPU Memory Usage:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Aggressively clear GPU memory\n",
    "    print(\"\\n⚠️  Clearing GPU memory...\")\n",
    "    \n",
    "    # Delete all variables in the current namespace that might hold GPU tensors\n",
    "    if 'model' in dir():\n",
    "        del model\n",
    "    if 'generator' in dir():\n",
    "        del generator\n",
    "    if 'sequences' in dir():\n",
    "        del sequences\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear PyTorch cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Reset peak memory stats\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.reset_accumulated_memory_stats()\n",
    "    \n",
    "    print(f\"\\nAfter clearing:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # If still not enough memory, suggest kernel restart\n",
    "    free_memory = (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3\n",
    "    if free_memory < 1.0:\n",
    "        print(\"\\n⚠️  WARNING: Very little GPU memory available!\")\n",
    "        print(\"   Consider: Kernel -> Restart Kernel to fully clear GPU memory\")\n",
    "else:\n",
    "    print(\"CUDA not available, will use CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4c4f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GPU Memory before setup:\n",
      "  Allocated: 0.08 GB\n",
      "  Reserved: 0.12 GB\n",
      "  Free: 15.50 GB\n",
      "\n",
      "============================================================\n",
      "Loading learned embeddings from LLM model...\n",
      "============================================================\n",
      "⚠️  WARNING: Failed to load embedding model: Error(s) in loading state_dict for Sudoku2Vec:\n",
      "\tUnexpected key(s) in state_dict: \"pe.pos_encoding\". \n",
      "   Falling back to simple normalization\n",
      "\n",
      "============================================================\n",
      "Pre-generating training dataset...\n",
      "============================================================\n",
      "Generating 10000 diffusion sequences...\n",
      "✓ Dataset generated in 131.69 seconds (13.17 ms per sequence)\n",
      "\n",
      "Dataset statistics:\n",
      "  Shape: torch.Size([10000, 82, 9, 9])\n",
      "  Memory: 253.37 MB\n",
      "  Device: cuda:0\n",
      "✓ Created SudokuDiffusionDataset with 10000 sequences\n",
      "\n",
      "============================================================\n",
      "Initializing Diffusion Model...\n",
      "============================================================\n",
      "✓ Model initialized successfully\n",
      "  Total parameters: 1,378,459\n",
      "  Trainable parameters: 1,378,459\n",
      "  Using embeddings: False\n",
      "\n",
      "GPU Memory after model loading:\n",
      "  Allocated: 0.34 GB\n",
      "  Reserved: 0.37 GB\n",
      "\n",
      "============================================================\n",
      "Starting Training...\n",
      "============================================================\n",
      "Starting training for 1000 epochs...\n",
      "Dataset size: 10000, Batch size: 1024, Batches per epoch: 10\n",
      "Learning rate: 0.0001\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m model, losses, accuracies = \u001b[43mtrain_sudoku_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_clip_max_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGRAD_CLIP_MAX_NORM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLOG_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEVAL_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 349\u001b[39m, in \u001b[36mtrain_sudoku_diffusion\u001b[39m\u001b[34m(model, dataset, num_epochs, batch_size, lr, weight_decay, grad_clip_max_norm, log_interval, eval_interval, k_max, device)\u001b[39m\n\u001b[32m    346\u001b[39m num_batches = \u001b[32m0\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# Iterate through batches in the dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute loss for this batch\u001b[39;49;00m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Backward pass\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/svi.on.mnist/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/svi.on.mnist/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:792\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    790\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/svi.on.mnist/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/pin_memory.py:66\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mRuntimeError\u001b[39m: cannot pin 'torch.cuda.IntTensor' only dense CPU tensors can be pinned"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Load embedding model and initialize components\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Clear GPU memory if using CUDA\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\nGPU Memory before setup:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved(0)) / 1024**3:.2f} GB\")\n",
    "\n",
    "# Load embedding model if configured\n",
    "embedding_layer = None\n",
    "if USE_LEARNED_EMBEDDINGS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Loading learned embeddings from LLM model...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    try:\n",
    "        sudoku2vec_model = Sudoku2Vec.load_model(EMBEDDING_MODEL_PATH, device=DEVICE)\n",
    "        embedding_layer = sudoku2vec_model.embed\n",
    "        print(f\"✓ Successfully loaded embedding layer with {embedding_layer.num_embeddings} tokens\")\n",
    "        print(f\"  Embedding dimension: {embedding_layer.embedding_dim}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️  WARNING: Embedding model not found at {EMBEDDING_MODEL_PATH}\")\n",
    "        print(\"   Falling back to simple normalization\")\n",
    "        USE_LEARNED_EMBEDDINGS = False\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  WARNING: Failed to load embedding model: {e}\")\n",
    "        print(\"   Falling back to simple normalization\")\n",
    "        USE_LEARNED_EMBEDDINGS = False\n",
    "else:\n",
    "    print(\"\\nUsing simple normalization (no learned embeddings)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PRE-GENERATE TRAINING DATASET\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Pre-generating training dataset...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Initialize generator\n",
    "generator = SudokuGenerator(backend='torch', device=DEVICE)\n",
    "\n",
    "# Generate diffusion sequences\n",
    "print(f\"Generating {DATASET_SIZE} diffusion sequences...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "sequences = generator.generate_diffusion_sequence(size=DATASET_SIZE)\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "print(f\"✓ Dataset generated in {generation_time:.2f} seconds ({generation_time/DATASET_SIZE*1000:.2f} ms per sequence)\")\n",
    "\n",
    "# Report dataset statistics\n",
    "sequence_shape = sequences.shape\n",
    "memory_mb = sequences.element_size() * sequences.nelement() / (1024 ** 2)\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"  Shape: {sequence_shape}\")\n",
    "print(f\"  Memory: {memory_mb:.2f} MB\")\n",
    "print(f\"  Device: {sequences.device}\")\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "train_dataset = SudokuDiffusionDataset(sequences)\n",
    "print(f\"✓ Created SudokuDiffusionDataset with {len(train_dataset)} sequences\")\n",
    "\n",
    "# Initialize model using configuration parameters\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Initializing Diffusion Model...\")\n",
    "print(f\"{'='*60}\")\n",
    "model = SudokuDiffusionModel(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    kernel_size=KERNEL_SIZE,\n",
    "    num_groups=NUM_GROUPS,\n",
    "    embedding_layer=embedding_layer,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"✓ Model initialized successfully\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Using embeddings: {model.use_embeddings}\")\n",
    "\n",
    "if DEVICE == 'cuda':\n",
    "    print(f\"\\nGPU Memory after model loading:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "# Train the model using configuration parameters\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Starting Training...\")\n",
    "print(f\"{'='*60}\")\n",
    "model, losses, accuracies = train_sudoku_diffusion(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    grad_clip_max_norm=GRAD_CLIP_MAX_NORM,\n",
    "    log_interval=LOG_INTERVAL,\n",
    "    eval_interval=EVAL_INTERVAL,\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c56309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
